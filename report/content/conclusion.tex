\section{Conclusion}\label{sec:conclusion}
The experiments above show that finding an optimal reparametrization of curves using neural networks is possible. The method approximates the optimal reparametrization of curves from the same shape and curves belonging to different shapes. We can also reparametrize curves with piecewise constant SRV form by optimizing a slightly different problem. Comparing methods, we see that our method performs worse than deep reparametrization \cite{j√∏rgen2021} on the test problem in Section \ref{subsec:case_1}. We are also able to approximate the optimal reparametrization of motion capture data. However, the resulting error was larger than the error produced by dynamic programming algorithm \cite{bauer2017dp}, but it was significantly faster.

From the experiments we also see that the optimization procedure is a big inhibitor of performance. One would expect as the width and depth of the networks increase. This happens up to a point, then the error to increase. Several aspects of training neural networks have not been discussed in this project. Firstly, the correctness of the resulting optimal reparametrization \(f_\theta\) varies by the initial conditions of the staring parameters \(\theta_0\). Thus, it would be fruitful to study whether some initialization procedures produce a consistently small error. Secondly, the structure of the neural networks has only been limited to comparing fully connected feedforward and residual networks. More exotic network structures could be easier to train and thus lead to better performance.


Smooth interpolation. failing 