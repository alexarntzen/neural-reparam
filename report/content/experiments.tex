
\section{Experiments}
There is a wide range of network structures and optimization algorithms. An in-depth search for the best parameters will not be the focus of this chapter. The main focus of this chapter will be to investigate when reparametrization by neural networks is possible and how it compares to other methods. For more information about implementation details, see Appendix \ref{sec:appendix}.

% We also investigate whether the type of error is optimization error or is approximation error. Thus, by the results in chapter \ref{subsec:neural-nets}, we investigate how increasing the network size impacts the resulting error. This approach will still be somewhat ambiguous; since increasing network size simultaneously increases the dimension of the optimization problem. 

% \todo{comment on vanishing gradient}

\todo{comment on ResNET and FFNN}

\subsection{Curves from the same shape}\label{subsec:case_1}
\input{content/experiments/case_1.tex}

\FloatBarrier
\subsection{Curves from different shapes}\label{subsec:case_2}
\input{content/experiments/case_2.tex}

\FloatBarrier
\subsection{Piecewise linear and piecewise constant}
\input{content/experiments/case_3.tex}

\FloatBarrier
\subsection{Interpolated motion capture data}
\input{content/experiments/case_4.tex}
