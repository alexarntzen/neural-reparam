{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Test reparam of curves that are not equivqalent \"\"\"\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# torch.set_default_dtype(torch.float64)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from deepthermal.FFNN_model import fit_FFNN, FFNN, init_xavier\n",
    "from deepthermal.validation import create_subdictionary_iterator, k_fold_cv_grid, add_dictionary_iterators\n",
    "\n",
    "from deepthermal.plotting import plot_result, plot_model_1d\n",
    "\n",
    "from deep_reparametrization.plotting import plot_reparametrization\n",
    "from deep_reparametrization.reparametrization import (\n",
    "    get_elastic_metric_loss,\n",
    "    compute_loss_reparam,\n",
    "    get_elastic_error_func,\n",
    ")\n",
    "from deep_reparametrization.ResNET import ResNET\n",
    "import test.curves_3 as c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "########\n",
    "PATH_FIGURES = \"../figures/curve_3\"\n",
    "########\n",
    "\n",
    "SET_NAME = \"curve_1_exp_1\"\n",
    "\n",
    "FOLDS = 1\n",
    "N = 128  # training points internal\n",
    "\n",
    "loss_func = get_elastic_metric_loss(r=c3.r, constrain_cost=1e3, verbose=False)\n",
    "MODEL_PARAMS = {\n",
    "    \"model\": [ResNET, FFNN],\n",
    "    \"input_dimension\": [1],\n",
    "    \"output_dimension\": [1],\n",
    "    \"activation\": [\"tanh\"],\n",
    "    \"n_hidden_layers\": [1, 2, 4, 16, 32, 64],\n",
    "}\n",
    "# extend the previous dict with the zip of this\n",
    "MODEL_PARAMS_EXPERIMENT = {\n",
    "    \"neurons\": [4, 8, 16, 32, 64, 128],\n",
    "}\n",
    "TRAINING_PARAMS = {\n",
    "    \"batch_size\": [N],\n",
    "    \"regularization_param\": [0],\n",
    "    \"compute_loss\": [compute_loss_reparam],\n",
    "    \"loss_func\": [loss_func],\n",
    "}\n",
    "# extend the previous dict with the zip of this\n",
    "TRAINING_PARAMS_EXPERIMENT = {\n",
    "    \"optimizer\": [\"strong_wolfe\"],\n",
    "    \"num_epochs\": [1],\n",
    "    \"learning_rate\": [ 0.01],\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Load data\n",
    "x_train = torch.linspace(0, 1, N, requires_grad=True).unsqueeze(1)\n",
    "q_train = c3.q(x_train.detach())\n",
    "\n",
    "\n",
    "data = TensorDataset(x_train, q_train)\n",
    "\n",
    "model_params_iter = create_subdictionary_iterator(MODEL_PARAMS)\n",
    "model_exp_iter = create_subdictionary_iterator(MODEL_PARAMS_EXPERIMENT, product=False)\n",
    "exp_model_params_iter = add_dictionary_iterators(model_exp_iter, model_params_iter)\n",
    "\n",
    "training_params_iter = create_subdictionary_iterator(TRAINING_PARAMS)\n",
    "training_exp_iter = create_subdictionary_iterator(TRAINING_PARAMS_EXPERIMENT, product=False)\n",
    "exp_training_params_iter = add_dictionary_iterators(training_exp_iter, training_params_iter)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Do the actual training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running model (trial=0, mod=0, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59574765\n",
      "Validation Loss:  0.59574771\n",
      "Final Training Loss:  0.59574765\n",
      "Final Validation Loss:  0.59574771\n",
      "\n",
      "Running model (trial=0, mod=1, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59814525\n",
      "Validation Loss:  0.59814525\n",
      "Final Training Loss:  0.59814525\n",
      "Final Validation Loss:  0.59814525\n",
      "\n",
      "Running model (trial=0, mod=2, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59508491\n",
      "Validation Loss:  0.59508491\n",
      "Final Training Loss:  0.59508491\n",
      "Final Validation Loss:  0.59508491\n",
      "\n",
      "Running model (trial=0, mod=3, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.63560987\n",
      "Validation Loss:  0.63560992\n",
      "Final Training Loss:  0.63560987\n",
      "Final Validation Loss:  0.63560992\n",
      "\n",
      "Running model (trial=0, mod=4, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60716939\n",
      "Validation Loss:  0.60716939\n",
      "Final Training Loss:  0.60716939\n",
      "Final Validation Loss:  0.60716939\n",
      "\n",
      "Running model (trial=0, mod=5, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.90296471\n",
      "Validation Loss:  0.90296465\n",
      "Final Training Loss:  0.90296471\n",
      "Final Validation Loss:  0.90296465\n",
      "\n",
      "Running model (trial=0, mod=6, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59185189\n",
      "Validation Loss:  0.59185195\n",
      "Final Training Loss:  0.59185189\n",
      "Final Validation Loss:  0.59185195\n",
      "\n",
      "Running model (trial=0, mod=7, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59027648\n",
      "Validation Loss:  0.59027648\n",
      "Final Training Loss:  0.59027648\n",
      "Final Validation Loss:  0.59027648\n",
      "\n",
      "Running model (trial=0, mod=8, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59419113\n",
      "Validation Loss:  0.59419125\n",
      "Final Training Loss:  0.59419113\n",
      "Final Validation Loss:  0.59419125\n",
      "\n",
      "Running model (trial=0, mod=9, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  500.99783325\n",
      "Validation Loss:  500.99783325\n",
      "Final Training Loss:  500.99783325\n",
      "Final Validation Loss:  500.99783325\n",
      "\n",
      "Running model (trial=0, mod=10, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.0\n",
      "Validation Loss:  501.0\n",
      "Final Training Loss:  501.0\n",
      "Final Validation Loss:  501.0\n",
      "\n",
      "Running model (trial=0, mod=11, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00006104\n",
      "Validation Loss:  501.00006104\n",
      "Final Training Loss:  501.00006104\n",
      "Final Validation Loss:  501.00006104\n",
      "\n",
      "Running model (trial=0, mod=12, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60556132\n",
      "Validation Loss:  0.60556144\n",
      "Final Training Loss:  0.60556132\n",
      "Final Validation Loss:  0.60556144\n",
      "\n",
      "Running model (trial=0, mod=13, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60661018\n",
      "Validation Loss:  0.60661018\n",
      "Final Training Loss:  0.60661018\n",
      "Final Validation Loss:  0.60661018\n",
      "\n",
      "Running model (trial=0, mod=14, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60551739\n",
      "Validation Loss:  0.60551745\n",
      "Final Training Loss:  0.60551739\n",
      "Final Validation Loss:  0.60551745\n",
      "\n",
      "Running model (trial=0, mod=15, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.61704177\n",
      "Validation Loss:  0.61704183\n",
      "Final Training Loss:  0.61704177\n",
      "Final Validation Loss:  0.61704183\n",
      "\n",
      "Running model (trial=0, mod=16, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.90375394\n",
      "Validation Loss:  0.90375388\n",
      "Final Training Loss:  0.90375394\n",
      "Final Validation Loss:  0.90375388\n",
      "\n",
      "Running model (trial=0, mod=17, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  20333.21679688\n",
      "Validation Loss:  20333.21679688\n",
      "Final Training Loss:  20333.21679688\n",
      "Final Validation Loss:  20333.21679688\n",
      "\n",
      "Running model (trial=0, mod=18, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60028464\n",
      "Validation Loss:  0.60028464\n",
      "Final Training Loss:  0.60028464\n",
      "Final Validation Loss:  0.60028464\n",
      "\n",
      "Running model (trial=0, mod=19, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59197867\n",
      "Validation Loss:  0.59197867\n",
      "Final Training Loss:  0.59197867\n",
      "Final Validation Loss:  0.59197867\n",
      "\n",
      "Running model (trial=0, mod=20, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.5954296\n",
      "Validation Loss:  0.59542954\n",
      "Final Training Loss:  0.5954296\n",
      "Final Validation Loss:  0.59542954\n",
      "\n",
      "Running model (trial=0, mod=21, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  500.99664307\n",
      "Validation Loss:  500.99664307\n",
      "Final Training Loss:  500.99664307\n",
      "Final Validation Loss:  500.99664307\n",
      "\n",
      "Running model (trial=0, mod=22, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00018311\n",
      "Validation Loss:  501.00018311\n",
      "Final Training Loss:  501.00018311\n",
      "Final Validation Loss:  501.00018311\n",
      "\n",
      "Running model (trial=0, mod=23, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00006104\n",
      "Validation Loss:  501.00006104\n",
      "Final Training Loss:  501.00006104\n",
      "Final Validation Loss:  501.00006104\n",
      "\n",
      "Running model (trial=0, mod=24, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.596156\n",
      "Validation Loss:  0.59615612\n",
      "Final Training Loss:  0.596156\n",
      "Final Validation Loss:  0.59615612\n",
      "\n",
      "Running model (trial=0, mod=25, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59952396\n",
      "Validation Loss:  0.5995239\n",
      "Final Training Loss:  0.59952396\n",
      "Final Validation Loss:  0.5995239\n",
      "\n",
      "Running model (trial=0, mod=26, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59846944\n",
      "Validation Loss:  0.59846944\n",
      "Final Training Loss:  0.59846944\n",
      "Final Validation Loss:  0.59846944\n",
      "\n",
      "Running model (trial=0, mod=27, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.66498458\n",
      "Validation Loss:  0.66498452\n",
      "Final Training Loss:  0.66498458\n",
      "Final Validation Loss:  0.66498452\n",
      "\n",
      "Running model (trial=0, mod=28, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.92096204\n",
      "Validation Loss:  0.92096198\n",
      "Final Training Loss:  0.92096204\n",
      "Final Validation Loss:  0.92096198\n",
      "\n",
      "Running model (trial=0, mod=29, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  88.74849701\n",
      "Validation Loss:  88.74849701\n",
      "Final Training Loss:  88.74849701\n",
      "Final Validation Loss:  88.74849701\n",
      "\n",
      "Running model (trial=0, mod=30, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60819149\n",
      "Validation Loss:  0.60819155\n",
      "Final Training Loss:  0.60819149\n",
      "Final Validation Loss:  0.60819155\n",
      "\n",
      "Running model (trial=0, mod=31, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59263676\n",
      "Validation Loss:  0.59263676\n",
      "Final Training Loss:  0.59263676\n",
      "Final Validation Loss:  0.59263676\n",
      "\n",
      "Running model (trial=0, mod=32, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59857965\n",
      "Validation Loss:  0.5985797\n",
      "Final Training Loss:  0.59857965\n",
      "Final Validation Loss:  0.5985797\n",
      "\n",
      "Running model (trial=0, mod=33, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59449863\n",
      "Validation Loss:  0.59449863\n",
      "Final Training Loss:  0.59449863\n",
      "Final Validation Loss:  0.59449863\n",
      "\n",
      "Running model (trial=0, mod=34, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00018311\n",
      "Validation Loss:  501.00018311\n",
      "Final Training Loss:  501.00018311\n",
      "Final Validation Loss:  501.00018311\n",
      "\n",
      "Running model (trial=0, mod=35, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.0\n",
      "Validation Loss:  501.0\n",
      "Final Training Loss:  501.0\n",
      "Final Validation Loss:  501.0\n",
      "\n",
      "Running model (trial=0, mod=36, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60081422\n",
      "Validation Loss:  0.60081422\n",
      "Final Training Loss:  0.60081422\n",
      "Final Validation Loss:  0.60081422\n",
      "\n",
      "Running model (trial=0, mod=37, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60076535\n",
      "Validation Loss:  0.60076541\n",
      "Final Training Loss:  0.60076535\n",
      "Final Validation Loss:  0.60076541\n",
      "\n",
      "Running model (trial=0, mod=38, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59725183\n",
      "Validation Loss:  0.59725177\n",
      "Final Training Loss:  0.59725183\n",
      "Final Validation Loss:  0.59725177\n",
      "\n",
      "Running model (trial=0, mod=39, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.87808686\n",
      "Validation Loss:  0.87808692\n",
      "Final Training Loss:  0.87808686\n",
      "Final Validation Loss:  0.87808692\n",
      "\n",
      "Running model (trial=0, mod=40, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  269.00253296\n",
      "Validation Loss:  269.00253296\n",
      "Final Training Loss:  269.00253296\n",
      "Final Validation Loss:  269.00253296\n",
      "\n",
      "Running model (trial=0, mod=41, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  12427.33789062\n",
      "Validation Loss:  12427.33789062\n",
      "Final Training Loss:  12427.33789062\n",
      "Final Validation Loss:  12427.33789062\n",
      "\n",
      "Running model (trial=0, mod=42, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60462868\n",
      "Validation Loss:  0.60462874\n",
      "Final Training Loss:  0.60462868\n",
      "Final Validation Loss:  0.60462874\n",
      "\n",
      "Running model (trial=0, mod=43, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.6018222\n",
      "Validation Loss:  0.6018222\n",
      "Final Training Loss:  0.6018222\n",
      "Final Validation Loss:  0.6018222\n",
      "\n",
      "Running model (trial=0, mod=44, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.5975045\n",
      "Validation Loss:  0.5975045\n",
      "Final Training Loss:  0.5975045\n",
      "Final Validation Loss:  0.5975045\n",
      "\n",
      "Running model (trial=0, mod=45, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.6008302\n",
      "Validation Loss:  0.60083026\n",
      "Final Training Loss:  0.6008302\n",
      "Final Validation Loss:  0.60083026\n",
      "\n",
      "Running model (trial=0, mod=46, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00024414\n",
      "Validation Loss:  501.00024414\n",
      "Final Training Loss:  501.00024414\n",
      "Final Validation Loss:  501.00024414\n",
      "\n",
      "Running model (trial=0, mod=47, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00018311\n",
      "Validation Loss:  501.00018311\n",
      "Final Training Loss:  501.00018311\n",
      "Final Validation Loss:  501.00018311\n",
      "\n",
      "Running model (trial=0, mod=48, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59724557\n",
      "Validation Loss:  0.59724557\n",
      "Final Training Loss:  0.59724557\n",
      "Final Validation Loss:  0.59724557\n",
      "\n",
      "Running model (trial=0, mod=49, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59693587\n",
      "Validation Loss:  0.59693581\n",
      "Final Training Loss:  0.59693587\n",
      "Final Validation Loss:  0.59693581\n",
      "\n",
      "Running model (trial=0, mod=50, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59455252\n",
      "Validation Loss:  0.59455252\n",
      "Final Training Loss:  0.59455252\n",
      "Final Validation Loss:  0.59455252\n",
      "\n",
      "Running model (trial=0, mod=51, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  13.99511623\n",
      "Validation Loss:  13.99511623\n",
      "Final Training Loss:  13.99511623\n",
      "Final Validation Loss:  13.99511623\n",
      "\n",
      "Running model (trial=0, mod=52, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  3427.89599609\n",
      "Validation Loss:  3427.89599609\n",
      "Final Training Loss:  3427.89599609\n",
      "Final Validation Loss:  3427.89599609\n",
      "\n",
      "Running model (trial=0, mod=53, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  49773.80078125\n",
      "Validation Loss:  49773.80078125\n",
      "Final Training Loss:  49773.80078125\n",
      "Final Validation Loss:  49773.80078125\n",
      "\n",
      "Running model (trial=0, mod=54, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60362101\n",
      "Validation Loss:  0.60362095\n",
      "Final Training Loss:  0.60362101\n",
      "Final Validation Loss:  0.60362095\n",
      "\n",
      "Running model (trial=0, mod=55, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60192758\n",
      "Validation Loss:  0.60192758\n",
      "Final Training Loss:  0.60192758\n",
      "Final Validation Loss:  0.60192758\n",
      "\n",
      "Running model (trial=0, mod=56, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59689349\n",
      "Validation Loss:  0.59689343\n",
      "Final Training Loss:  0.59689349\n",
      "Final Validation Loss:  0.59689343\n",
      "\n",
      "Running model (trial=0, mod=57, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.61516547\n",
      "Validation Loss:  0.61516547\n",
      "Final Training Loss:  0.61516547\n",
      "Final Validation Loss:  0.61516547\n",
      "\n",
      "Running model (trial=0, mod=58, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00115967\n",
      "Validation Loss:  501.00115967\n",
      "Final Training Loss:  501.00115967\n",
      "Final Validation Loss:  501.00115967\n",
      "\n",
      "Running model (trial=0, mod=59, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00012207\n",
      "Validation Loss:  501.00012207\n",
      "Final Training Loss:  501.00012207\n",
      "Final Validation Loss:  501.00012207\n",
      "\n",
      "Running model (trial=0, mod=60, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60052657\n",
      "Validation Loss:  0.60052651\n",
      "Final Training Loss:  0.60052657\n",
      "Final Validation Loss:  0.60052651\n",
      "\n",
      "Running model (trial=0, mod=61, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59591109\n",
      "Validation Loss:  0.59591115\n",
      "Final Training Loss:  0.59591109\n",
      "Final Validation Loss:  0.59591115\n",
      "\n",
      "Running model (trial=0, mod=62, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59497374\n",
      "Validation Loss:  0.5949738\n",
      "Final Training Loss:  0.59497374\n",
      "Final Validation Loss:  0.5949738\n",
      "\n",
      "Running model (trial=0, mod=63, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59707588\n",
      "Validation Loss:  0.59707594\n",
      "Final Training Loss:  0.59707588\n",
      "Final Validation Loss:  0.59707594\n",
      "\n",
      "Running model (trial=0, mod=64, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  91.29047394\n",
      "Validation Loss:  91.29047394\n",
      "Final Training Loss:  91.29047394\n",
      "Final Validation Loss:  91.29047394\n",
      "\n",
      "Running model (trial=0, mod=65, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  1581.12683105\n",
      "Validation Loss:  1581.12683105\n",
      "Final Training Loss:  1581.12683105\n",
      "Final Validation Loss:  1581.12683105\n",
      "\n",
      "Running model (trial=0, mod=66, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59694582\n",
      "Validation Loss:  0.59694582\n",
      "Final Training Loss:  0.59694582\n",
      "Final Validation Loss:  0.59694582\n",
      "\n",
      "Running model (trial=0, mod=67, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60019076\n",
      "Validation Loss:  0.60019076\n",
      "Final Training Loss:  0.60019076\n",
      "Final Validation Loss:  0.60019076\n",
      "\n",
      "Running model (trial=0, mod=68, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60358924\n",
      "Validation Loss:  0.6035893\n",
      "Final Training Loss:  0.60358924\n",
      "Final Validation Loss:  0.6035893\n",
      "\n",
      "Running model (trial=0, mod=69, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59453225\n",
      "Validation Loss:  0.59453225\n",
      "Final Training Loss:  0.59453225\n",
      "Final Validation Loss:  0.59453225\n",
      "\n",
      "Running model (trial=0, mod=70, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00076294\n",
      "Validation Loss:  501.00076294\n",
      "Final Training Loss:  501.00076294\n",
      "Final Validation Loss:  501.00076294\n",
      "\n",
      "Running model (trial=0, mod=71, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00012207\n",
      "Validation Loss:  501.00012207\n",
      "Final Training Loss:  501.00012207\n",
      "Final Validation Loss:  501.00012207\n",
      "\n",
      "Running model (trial=1, mod=72, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.63316667\n",
      "Validation Loss:  0.63316667\n",
      "Final Training Loss:  0.63316667\n",
      "Final Validation Loss:  0.63316667\n",
      "\n",
      "Running model (trial=1, mod=73, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59595025\n",
      "Validation Loss:  0.59595025\n",
      "Final Training Loss:  0.59595025\n",
      "Final Validation Loss:  0.59595025\n",
      "\n",
      "Running model (trial=1, mod=74, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60626441\n",
      "Validation Loss:  0.60626435\n",
      "Final Training Loss:  0.60626441\n",
      "Final Validation Loss:  0.60626435\n",
      "\n",
      "Running model (trial=1, mod=75, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.66792035\n",
      "Validation Loss:  0.66792041\n",
      "Final Training Loss:  0.66792035\n",
      "Final Validation Loss:  0.66792041\n",
      "\n",
      "Running model (trial=1, mod=76, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60041916\n",
      "Validation Loss:  0.6004191\n",
      "Final Training Loss:  0.60041916\n",
      "Final Validation Loss:  0.6004191\n",
      "\n",
      "Running model (trial=1, mod=77, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  1.01102722\n",
      "Validation Loss:  1.01102722\n",
      "Final Training Loss:  1.01102722\n",
      "Final Validation Loss:  1.01102722\n",
      "\n",
      "Running model (trial=1, mod=78, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59198999\n",
      "Validation Loss:  0.59198999\n",
      "Final Training Loss:  0.59198999\n",
      "Final Validation Loss:  0.59198999\n",
      "\n",
      "Running model (trial=1, mod=79, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59523267\n",
      "Validation Loss:  0.59523261\n",
      "Final Training Loss:  0.59523267\n",
      "Final Validation Loss:  0.59523261\n",
      "\n",
      "Running model (trial=1, mod=80, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59388787\n",
      "Validation Loss:  0.59388787\n",
      "Final Training Loss:  0.59388787\n",
      "Final Validation Loss:  0.59388787\n",
      "\n",
      "Running model (trial=1, mod=81, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.02981567\n",
      "Validation Loss:  501.02981567\n",
      "Final Training Loss:  501.02981567\n",
      "Final Validation Loss:  501.02981567\n",
      "\n",
      "Running model (trial=1, mod=82, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00006104\n",
      "Validation Loss:  501.00006104\n",
      "Final Training Loss:  501.00006104\n",
      "Final Validation Loss:  501.00006104\n",
      "\n",
      "Running model (trial=1, mod=83, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.0\n",
      "Validation Loss:  501.0\n",
      "Final Training Loss:  501.0\n",
      "Final Validation Loss:  501.0\n",
      "\n",
      "Running model (trial=1, mod=84, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59656006\n",
      "Validation Loss:  0.59656006\n",
      "Final Training Loss:  0.59656006\n",
      "Final Validation Loss:  0.59656006\n",
      "\n",
      "Running model (trial=1, mod=85, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60516649\n",
      "Validation Loss:  0.60516661\n",
      "Final Training Loss:  0.60516649\n",
      "Final Validation Loss:  0.60516661\n",
      "\n",
      "Running model (trial=1, mod=86, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59260494\n",
      "Validation Loss:  0.59260494\n",
      "Final Training Loss:  0.59260494\n",
      "Final Validation Loss:  0.59260494\n",
      "\n",
      "Running model (trial=1, mod=87, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  1.20208812\n",
      "Validation Loss:  1.20208824\n",
      "Final Training Loss:  1.20208812\n",
      "Final Validation Loss:  1.20208824\n",
      "\n",
      "Running model (trial=1, mod=88, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  17103.18359375\n",
      "Validation Loss:  17103.18359375\n",
      "Final Training Loss:  17103.18359375\n",
      "Final Validation Loss:  17103.18359375\n",
      "\n",
      "Running model (trial=1, mod=89, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  1016298.6875\n",
      "Validation Loss:  1016298.6875\n",
      "Final Training Loss:  1016298.6875\n",
      "Final Validation Loss:  1016298.6875\n",
      "\n",
      "Running model (trial=1, mod=90, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59812874\n",
      "Validation Loss:  0.5981288\n",
      "Final Training Loss:  0.59812874\n",
      "Final Validation Loss:  0.5981288\n",
      "\n",
      "Running model (trial=1, mod=91, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59967488\n",
      "Validation Loss:  0.59967494\n",
      "Final Training Loss:  0.59967488\n",
      "Final Validation Loss:  0.59967494\n",
      "\n",
      "Running model (trial=1, mod=92, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59410101\n",
      "Validation Loss:  0.59410101\n",
      "Final Training Loss:  0.59410101\n",
      "Final Validation Loss:  0.59410101\n",
      "\n",
      "Running model (trial=1, mod=93, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  500.9944458\n",
      "Validation Loss:  500.9944458\n",
      "Final Training Loss:  500.9944458\n",
      "Final Validation Loss:  500.9944458\n",
      "\n",
      "Running model (trial=1, mod=94, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.0\n",
      "Validation Loss:  501.0\n",
      "Final Training Loss:  501.0\n",
      "Final Validation Loss:  501.0\n",
      "\n",
      "Running model (trial=1, mod=95, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00012207\n",
      "Validation Loss:  501.00012207\n",
      "Final Training Loss:  501.00012207\n",
      "Final Validation Loss:  501.00012207\n",
      "\n",
      "Running model (trial=1, mod=96, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.5944488\n",
      "Validation Loss:  0.59444886\n",
      "Final Training Loss:  0.5944488\n",
      "Final Validation Loss:  0.59444886\n",
      "\n",
      "Running model (trial=1, mod=97, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60398185\n",
      "Validation Loss:  0.60398191\n",
      "Final Training Loss:  0.60398185\n",
      "Final Validation Loss:  0.60398191\n",
      "\n",
      "Running model (trial=1, mod=98, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59910542\n",
      "Validation Loss:  0.59910548\n",
      "Final Training Loss:  0.59910542\n",
      "Final Validation Loss:  0.59910548\n",
      "\n",
      "Running model (trial=1, mod=99, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60311067\n",
      "Validation Loss:  0.60311067\n",
      "Final Training Loss:  0.60311067\n",
      "Final Validation Loss:  0.60311067\n",
      "\n",
      "Running model (trial=1, mod=100, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  1.07271659\n",
      "Validation Loss:  1.07271659\n",
      "Final Training Loss:  1.07271659\n",
      "Final Validation Loss:  1.07271659\n",
      "\n",
      "Running model (trial=1, mod=101, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  2524.19140625\n",
      "Validation Loss:  2524.19140625\n",
      "Final Training Loss:  2524.19140625\n",
      "Final Validation Loss:  2524.19140625\n",
      "\n",
      "Running model (trial=1, mod=102, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.6050306\n",
      "Validation Loss:  0.60503066\n",
      "Final Training Loss:  0.6050306\n",
      "Final Validation Loss:  0.60503066\n",
      "\n",
      "Running model (trial=1, mod=103, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.61256808\n",
      "Validation Loss:  0.61256808\n",
      "Final Training Loss:  0.61256808\n",
      "Final Validation Loss:  0.61256808\n",
      "\n",
      "Running model (trial=1, mod=104, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59381968\n",
      "Validation Loss:  0.59381974\n",
      "Final Training Loss:  0.59381968\n",
      "Final Validation Loss:  0.59381974\n",
      "\n",
      "Running model (trial=1, mod=105, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.61114269\n",
      "Validation Loss:  0.61114258\n",
      "Final Training Loss:  0.61114269\n",
      "Final Validation Loss:  0.61114258\n",
      "\n",
      "Running model (trial=1, mod=106, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00030518\n",
      "Validation Loss:  501.00030518\n",
      "Final Training Loss:  501.00030518\n",
      "Final Validation Loss:  501.00030518\n",
      "\n",
      "Running model (trial=1, mod=107, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00012207\n",
      "Validation Loss:  501.00012207\n",
      "Final Training Loss:  501.00012207\n",
      "Final Validation Loss:  501.00012207\n",
      "\n",
      "Running model (trial=1, mod=108, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59540659\n",
      "Validation Loss:  0.59540647\n",
      "Final Training Loss:  0.59540659\n",
      "Final Validation Loss:  0.59540647\n",
      "\n",
      "Running model (trial=1, mod=109, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60384995\n",
      "Validation Loss:  0.60384995\n",
      "Final Training Loss:  0.60384995\n",
      "Final Validation Loss:  0.60384995\n",
      "\n",
      "Running model (trial=1, mod=110, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60457891\n",
      "Validation Loss:  0.60457891\n",
      "Final Training Loss:  0.60457891\n",
      "Final Validation Loss:  0.60457891\n",
      "\n",
      "Running model (trial=1, mod=111, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.67621434\n",
      "Validation Loss:  0.6762144\n",
      "Final Training Loss:  0.67621434\n",
      "Final Validation Loss:  0.6762144\n",
      "\n",
      "Running model (trial=1, mod=112, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  19.9257164\n",
      "Validation Loss:  19.9257164\n",
      "Final Training Loss:  19.9257164\n",
      "Final Validation Loss:  19.9257164\n",
      "\n",
      "Running model (trial=1, mod=113, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  3779.02563477\n",
      "Validation Loss:  3779.02563477\n",
      "Final Training Loss:  3779.02563477\n",
      "Final Validation Loss:  3779.02563477\n",
      "\n",
      "Running model (trial=1, mod=114, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59818202\n",
      "Validation Loss:  0.59818202\n",
      "Final Training Loss:  0.59818202\n",
      "Final Validation Loss:  0.59818202\n",
      "\n",
      "Running model (trial=1, mod=115, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.61267477\n",
      "Validation Loss:  0.61267477\n",
      "Final Training Loss:  0.61267477\n",
      "Final Validation Loss:  0.61267477\n",
      "\n",
      "Running model (trial=1, mod=116, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59306335\n",
      "Validation Loss:  0.59306341\n",
      "Final Training Loss:  0.59306335\n",
      "Final Validation Loss:  0.59306341\n",
      "\n",
      "Running model (trial=1, mod=117, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  1.06420302\n",
      "Validation Loss:  1.0642029\n",
      "Final Training Loss:  1.06420302\n",
      "Final Validation Loss:  1.0642029\n",
      "\n",
      "Running model (trial=1, mod=118, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.0\n",
      "Validation Loss:  501.0\n",
      "Final Training Loss:  501.0\n",
      "Final Validation Loss:  501.0\n",
      "\n",
      "Running model (trial=1, mod=119, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00024414\n",
      "Validation Loss:  501.00024414\n",
      "Final Training Loss:  501.00024414\n",
      "Final Validation Loss:  501.00024414\n",
      "\n",
      "Running model (trial=1, mod=120, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59820795\n",
      "Validation Loss:  0.59820801\n",
      "Final Training Loss:  0.59820795\n",
      "Final Validation Loss:  0.59820801\n",
      "\n",
      "Running model (trial=1, mod=121, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59565091\n",
      "Validation Loss:  0.59565097\n",
      "Final Training Loss:  0.59565091\n",
      "Final Validation Loss:  0.59565097\n",
      "\n",
      "Running model (trial=1, mod=122, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59698862\n",
      "Validation Loss:  0.59698862\n",
      "Final Training Loss:  0.59698862\n",
      "Final Validation Loss:  0.59698862\n",
      "\n",
      "Running model (trial=1, mod=123, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59063065\n",
      "Validation Loss:  0.59063065\n",
      "Final Training Loss:  0.59063065\n",
      "Final Validation Loss:  0.59063065\n",
      "\n",
      "Running model (trial=1, mod=124, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.7586205\n",
      "Validation Loss:  0.75862056\n",
      "Final Training Loss:  0.7586205\n",
      "Final Validation Loss:  0.75862056\n",
      "\n",
      "Running model (trial=1, mod=125, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  1893.08337402\n",
      "Validation Loss:  1893.08337402\n",
      "Final Training Loss:  1893.08337402\n",
      "Final Validation Loss:  1893.08337402\n",
      "\n",
      "Running model (trial=1, mod=126, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59909528\n",
      "Validation Loss:  0.5990954\n",
      "Final Training Loss:  0.59909528\n",
      "Final Validation Loss:  0.5990954\n",
      "\n",
      "Running model (trial=1, mod=127, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59723961\n",
      "Validation Loss:  0.59723961\n",
      "Final Training Loss:  0.59723961\n",
      "Final Validation Loss:  0.59723961\n",
      "\n",
      "Running model (trial=1, mod=128, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59277439\n",
      "Validation Loss:  0.59277439\n",
      "Final Training Loss:  0.59277439\n",
      "Final Validation Loss:  0.59277439\n",
      "\n",
      "Running model (trial=1, mod=129, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59248114\n",
      "Validation Loss:  0.59248114\n",
      "Final Training Loss:  0.59248114\n",
      "Final Validation Loss:  0.59248114\n",
      "\n",
      "Running model (trial=1, mod=130, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00024414\n",
      "Validation Loss:  501.00024414\n",
      "Final Training Loss:  501.00024414\n",
      "Final Validation Loss:  501.00024414\n",
      "\n",
      "Running model (trial=1, mod=131, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00006104\n",
      "Validation Loss:  501.00006104\n",
      "Final Training Loss:  501.00006104\n",
      "Final Validation Loss:  501.00006104\n",
      "\n",
      "Running model (trial=1, mod=132, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60029566\n",
      "Validation Loss:  0.60029566\n",
      "Final Training Loss:  0.60029566\n",
      "Final Validation Loss:  0.60029566\n",
      "\n",
      "Running model (trial=1, mod=133, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59524995\n",
      "Validation Loss:  0.59524995\n",
      "Final Training Loss:  0.59524995\n",
      "Final Validation Loss:  0.59524995\n",
      "\n",
      "Running model (trial=1, mod=134, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59476095\n",
      "Validation Loss:  0.59476095\n",
      "Final Training Loss:  0.59476095\n",
      "Final Validation Loss:  0.59476095\n",
      "\n",
      "Running model (trial=1, mod=135, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60322195\n",
      "Validation Loss:  0.60322195\n",
      "Final Training Loss:  0.60322195\n",
      "Final Validation Loss:  0.60322195\n",
      "\n",
      "Running model (trial=1, mod=136, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  1.14460576\n",
      "Validation Loss:  1.14460576\n",
      "Final Training Loss:  1.14460576\n",
      "Final Validation Loss:  1.14460576\n",
      "\n",
      "Running model (trial=1, mod=137, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  31936.40039062\n",
      "Validation Loss:  31936.40039062\n",
      "Final Training Loss:  31936.40039062\n",
      "Final Validation Loss:  31936.40039062\n",
      "\n",
      "Running model (trial=1, mod=138, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59503531\n",
      "Validation Loss:  0.59503531\n",
      "Final Training Loss:  0.59503531\n",
      "Final Validation Loss:  0.59503531\n",
      "\n",
      "Running model (trial=1, mod=139, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59648567\n",
      "Validation Loss:  0.59648567\n",
      "Final Training Loss:  0.59648567\n",
      "Final Validation Loss:  0.59648567\n",
      "\n",
      "Running model (trial=1, mod=140, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60068905\n",
      "Validation Loss:  0.60068917\n",
      "Final Training Loss:  0.60068905\n",
      "Final Validation Loss:  0.60068917\n",
      "\n",
      "Running model (trial=1, mod=141, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.61200041\n",
      "Validation Loss:  0.61200035\n",
      "Final Training Loss:  0.61200041\n",
      "Final Validation Loss:  0.61200035\n",
      "\n",
      "Running model (trial=1, mod=142, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00009155\n",
      "Validation Loss:  501.00009155\n",
      "Final Training Loss:  501.00009155\n",
      "Final Validation Loss:  501.00009155\n",
      "\n",
      "Running model (trial=1, mod=143, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00012207\n",
      "Validation Loss:  501.00012207\n",
      "Final Training Loss:  501.00012207\n",
      "Final Validation Loss:  501.00012207\n",
      "\n",
      "Running model (trial=2, mod=144, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59781975\n",
      "Validation Loss:  0.59781969\n",
      "Final Training Loss:  0.59781975\n",
      "Final Validation Loss:  0.59781969\n",
      "\n",
      "Running model (trial=2, mod=145, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59212446\n",
      "Validation Loss:  0.59212446\n",
      "Final Training Loss:  0.59212446\n",
      "Final Validation Loss:  0.59212446\n",
      "\n",
      "Running model (trial=2, mod=146, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60068953\n",
      "Validation Loss:  0.60068953\n",
      "Final Training Loss:  0.60068953\n",
      "Final Validation Loss:  0.60068953\n",
      "\n",
      "Running model (trial=2, mod=147, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59662813\n",
      "Validation Loss:  0.59662819\n",
      "Final Training Loss:  0.59662813\n",
      "Final Validation Loss:  0.59662819\n",
      "\n",
      "Running model (trial=2, mod=148, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.77196956\n",
      "Validation Loss:  0.77196962\n",
      "Final Training Loss:  0.77196956\n",
      "Final Validation Loss:  0.77196962\n",
      "\n",
      "Running model (trial=2, mod=149, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.58929998\n",
      "Validation Loss:  0.58929998\n",
      "Final Training Loss:  0.58929998\n",
      "Final Validation Loss:  0.58929998\n",
      "\n",
      "Running model (trial=2, mod=150, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59728235\n",
      "Validation Loss:  0.59728235\n",
      "Final Training Loss:  0.59728235\n",
      "Final Validation Loss:  0.59728235\n",
      "\n",
      "Running model (trial=2, mod=151, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59513569\n",
      "Validation Loss:  0.59513575\n",
      "Final Training Loss:  0.59513569\n",
      "Final Validation Loss:  0.59513575\n",
      "\n",
      "Running model (trial=2, mod=152, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59499836\n",
      "Validation Loss:  0.59499836\n",
      "Final Training Loss:  0.59499836\n",
      "Final Validation Loss:  0.59499836\n",
      "\n",
      "Running model (trial=2, mod=153, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  500.99908447\n",
      "Validation Loss:  500.99908447\n",
      "Final Training Loss:  500.99908447\n",
      "Final Validation Loss:  500.99908447\n",
      "\n",
      "Running model (trial=2, mod=154, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00018311\n",
      "Validation Loss:  501.00018311\n",
      "Final Training Loss:  501.00018311\n",
      "Final Validation Loss:  501.00018311\n",
      "\n",
      "Running model (trial=2, mod=155, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00012207\n",
      "Validation Loss:  501.00012207\n",
      "Final Training Loss:  501.00012207\n",
      "Final Validation Loss:  501.00012207\n",
      "\n",
      "Running model (trial=2, mod=156, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.5976035\n",
      "Validation Loss:  0.5976035\n",
      "Final Training Loss:  0.5976035\n",
      "Final Validation Loss:  0.5976035\n",
      "\n",
      "Running model (trial=2, mod=157, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60898602\n",
      "Validation Loss:  0.60898602\n",
      "Final Training Loss:  0.60898602\n",
      "Final Validation Loss:  0.60898602\n",
      "\n",
      "Running model (trial=2, mod=158, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59673238\n",
      "Validation Loss:  0.5967325\n",
      "Final Training Loss:  0.59673238\n",
      "Final Validation Loss:  0.5967325\n",
      "\n",
      "Running model (trial=2, mod=159, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.62918347\n",
      "Validation Loss:  0.62918353\n",
      "Final Training Loss:  0.62918347\n",
      "Final Validation Loss:  0.62918353\n",
      "\n",
      "Running model (trial=2, mod=160, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  1073.96166992\n",
      "Validation Loss:  1073.96166992\n",
      "Final Training Loss:  1073.96166992\n",
      "Final Validation Loss:  1073.96166992\n",
      "\n",
      "Running model (trial=2, mod=161, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.62553883\n",
      "Validation Loss:  0.62553889\n",
      "Final Training Loss:  0.62553883\n",
      "Final Validation Loss:  0.62553889\n",
      "\n",
      "Running model (trial=2, mod=162, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.5988993\n",
      "Validation Loss:  0.59889936\n",
      "Final Training Loss:  0.5988993\n",
      "Final Validation Loss:  0.59889936\n",
      "\n",
      "Running model (trial=2, mod=163, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59712505\n",
      "Validation Loss:  0.59712505\n",
      "Final Training Loss:  0.59712505\n",
      "Final Validation Loss:  0.59712505\n",
      "\n",
      "Running model (trial=2, mod=164, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.5965572\n",
      "Validation Loss:  0.5965572\n",
      "Final Training Loss:  0.5965572\n",
      "Final Validation Loss:  0.5965572\n",
      "\n",
      "Running model (trial=2, mod=165, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  500.99526978\n",
      "Validation Loss:  500.99526978\n",
      "Final Training Loss:  500.99526978\n",
      "Final Validation Loss:  500.99526978\n",
      "\n",
      "Running model (trial=2, mod=166, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00006104\n",
      "Validation Loss:  501.00006104\n",
      "Final Training Loss:  501.00006104\n",
      "Final Validation Loss:  501.00006104\n",
      "\n",
      "Running model (trial=2, mod=167, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00012207\n",
      "Validation Loss:  501.00012207\n",
      "Final Training Loss:  501.00012207\n",
      "Final Validation Loss:  501.00012207\n",
      "\n",
      "Running model (trial=2, mod=168, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60355997\n",
      "Validation Loss:  0.60355997\n",
      "Final Training Loss:  0.60355997\n",
      "Final Validation Loss:  0.60355997\n",
      "\n",
      "Running model (trial=2, mod=169, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60239494\n",
      "Validation Loss:  0.60239494\n",
      "Final Training Loss:  0.60239494\n",
      "Final Validation Loss:  0.60239494\n",
      "\n",
      "Running model (trial=2, mod=170, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59703404\n",
      "Validation Loss:  0.59703398\n",
      "Final Training Loss:  0.59703404\n",
      "Final Validation Loss:  0.59703398\n",
      "\n",
      "Running model (trial=2, mod=171, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60854816\n",
      "Validation Loss:  0.6085481\n",
      "Final Training Loss:  0.60854816\n",
      "Final Validation Loss:  0.6085481\n",
      "\n",
      "Running model (trial=2, mod=172, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.98808146\n",
      "Validation Loss:  0.9880814\n",
      "Final Training Loss:  0.98808146\n",
      "Final Validation Loss:  0.9880814\n",
      "\n",
      "Running model (trial=2, mod=173, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  118.46857452\n",
      "Validation Loss:  118.46857452\n",
      "Final Training Loss:  118.46857452\n",
      "Final Validation Loss:  118.46857452\n",
      "\n",
      "Running model (trial=2, mod=174, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59955585\n",
      "Validation Loss:  0.59955579\n",
      "Final Training Loss:  0.59955585\n",
      "Final Validation Loss:  0.59955579\n",
      "\n",
      "Running model (trial=2, mod=175, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59481847\n",
      "Validation Loss:  0.59481847\n",
      "Final Training Loss:  0.59481847\n",
      "Final Validation Loss:  0.59481847\n",
      "\n",
      "Running model (trial=2, mod=176, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59733862\n",
      "Validation Loss:  0.59733862\n",
      "Final Training Loss:  0.59733862\n",
      "Final Validation Loss:  0.59733862\n",
      "\n",
      "Running model (trial=2, mod=177, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  500.98657227\n",
      "Validation Loss:  500.98657227\n",
      "Final Training Loss:  500.98657227\n",
      "Final Validation Loss:  500.98657227\n",
      "\n",
      "Running model (trial=2, mod=178, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00054932\n",
      "Validation Loss:  501.00054932\n",
      "Final Training Loss:  501.00054932\n",
      "Final Validation Loss:  501.00054932\n",
      "\n",
      "Running model (trial=2, mod=179, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00030518\n",
      "Validation Loss:  501.00030518\n",
      "Final Training Loss:  501.00030518\n",
      "Final Validation Loss:  501.00030518\n",
      "\n",
      "Running model (trial=2, mod=180, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59584433\n",
      "Validation Loss:  0.59584427\n",
      "Final Training Loss:  0.59584433\n",
      "Final Validation Loss:  0.59584427\n",
      "\n",
      "Running model (trial=2, mod=181, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59489137\n",
      "Validation Loss:  0.59489137\n",
      "Final Training Loss:  0.59489137\n",
      "Final Validation Loss:  0.59489137\n",
      "\n",
      "Running model (trial=2, mod=182, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59901702\n",
      "Validation Loss:  0.59901708\n",
      "Final Training Loss:  0.59901702\n",
      "Final Validation Loss:  0.59901708\n",
      "\n",
      "Running model (trial=2, mod=183, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.71369869\n",
      "Validation Loss:  0.71369869\n",
      "Final Training Loss:  0.71369869\n",
      "Final Validation Loss:  0.71369869\n",
      "\n",
      "Running model (trial=2, mod=184, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  223.89105225\n",
      "Validation Loss:  223.89105225\n",
      "Final Training Loss:  223.89105225\n",
      "Final Validation Loss:  223.89105225\n",
      "\n",
      "Running model (trial=2, mod=185, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  69225.671875\n",
      "Validation Loss:  69225.671875\n",
      "Final Training Loss:  69225.671875\n",
      "Final Validation Loss:  69225.671875\n",
      "\n",
      "Running model (trial=2, mod=186, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60873693\n",
      "Validation Loss:  0.60873693\n",
      "Final Training Loss:  0.60873693\n",
      "Final Validation Loss:  0.60873693\n",
      "\n",
      "Running model (trial=2, mod=187, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60402304\n",
      "Validation Loss:  0.6040231\n",
      "Final Training Loss:  0.60402304\n",
      "Final Validation Loss:  0.6040231\n",
      "\n",
      "Running model (trial=2, mod=188, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59379631\n",
      "Validation Loss:  0.59379637\n",
      "Final Training Loss:  0.59379631\n",
      "Final Validation Loss:  0.59379637\n",
      "\n",
      "Running model (trial=2, mod=189, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  500.99151611\n",
      "Validation Loss:  500.99151611\n",
      "Final Training Loss:  500.99151611\n",
      "Final Validation Loss:  500.99151611\n",
      "\n",
      "Running model (trial=2, mod=190, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00033569\n",
      "Validation Loss:  501.00033569\n",
      "Final Training Loss:  501.00033569\n",
      "Final Validation Loss:  501.00033569\n",
      "\n",
      "Running model (trial=2, mod=191, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00006104\n",
      "Validation Loss:  501.00006104\n",
      "Final Training Loss:  501.00006104\n",
      "Final Validation Loss:  501.00006104\n",
      "\n",
      "Running model (trial=2, mod=192, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59673798\n",
      "Validation Loss:  0.59673804\n",
      "Final Training Loss:  0.59673798\n",
      "Final Validation Loss:  0.59673804\n",
      "\n",
      "Running model (trial=2, mod=193, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59754384\n",
      "Validation Loss:  0.59754384\n",
      "Final Training Loss:  0.59754384\n",
      "Final Validation Loss:  0.59754384\n",
      "\n",
      "Running model (trial=2, mod=194, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59504026\n",
      "Validation Loss:  0.59504032\n",
      "Final Training Loss:  0.59504026\n",
      "Final Validation Loss:  0.59504032\n",
      "\n",
      "Running model (trial=2, mod=195, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59031254\n",
      "Validation Loss:  0.59031254\n",
      "Final Training Loss:  0.59031254\n",
      "Final Validation Loss:  0.59031254\n",
      "\n",
      "Running model (trial=2, mod=196, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.90753305\n",
      "Validation Loss:  0.90753299\n",
      "Final Training Loss:  0.90753305\n",
      "Final Validation Loss:  0.90753299\n",
      "\n",
      "Running model (trial=2, mod=197, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  4518.34765625\n",
      "Validation Loss:  4518.34765625\n",
      "Final Training Loss:  4518.34765625\n",
      "Final Validation Loss:  4518.34765625\n",
      "\n",
      "Running model (trial=2, mod=198, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59600675\n",
      "Validation Loss:  0.59600669\n",
      "Final Training Loss:  0.59600675\n",
      "Final Validation Loss:  0.59600669\n",
      "\n",
      "Running model (trial=2, mod=199, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.597449\n",
      "Validation Loss:  0.597449\n",
      "Final Training Loss:  0.597449\n",
      "Final Validation Loss:  0.597449\n",
      "\n",
      "Running model (trial=2, mod=200, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59758484\n",
      "Validation Loss:  0.59758484\n",
      "Final Training Loss:  0.59758484\n",
      "Final Validation Loss:  0.59758484\n",
      "\n",
      "Running model (trial=2, mod=201, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59870714\n",
      "Validation Loss:  0.59870714\n",
      "Final Training Loss:  0.59870714\n",
      "Final Validation Loss:  0.59870714\n",
      "\n",
      "Running model (trial=2, mod=202, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00006104\n",
      "Validation Loss:  501.00006104\n",
      "Final Training Loss:  501.00006104\n",
      "Final Validation Loss:  501.00006104\n",
      "\n",
      "Running model (trial=2, mod=203, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00012207\n",
      "Validation Loss:  501.00012207\n",
      "Final Training Loss:  501.00012207\n",
      "Final Validation Loss:  501.00012207\n",
      "\n",
      "Running model (trial=2, mod=204, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60330379\n",
      "Validation Loss:  0.60330379\n",
      "Final Training Loss:  0.60330379\n",
      "Final Validation Loss:  0.60330379\n",
      "\n",
      "Running model (trial=2, mod=205, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59924555\n",
      "Validation Loss:  0.59924555\n",
      "Final Training Loss:  0.59924555\n",
      "Final Validation Loss:  0.59924555\n",
      "\n",
      "Running model (trial=2, mod=206, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59320635\n",
      "Validation Loss:  0.59320635\n",
      "Final Training Loss:  0.59320635\n",
      "Final Validation Loss:  0.59320635\n",
      "\n",
      "Running model (trial=2, mod=207, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.61090589\n",
      "Validation Loss:  0.61090583\n",
      "Final Training Loss:  0.61090589\n",
      "Final Validation Loss:  0.61090583\n",
      "\n",
      "Running model (trial=2, mod=208, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  228.66973877\n",
      "Validation Loss:  228.66973877\n",
      "Final Training Loss:  228.66973877\n",
      "Final Validation Loss:  228.66973877\n",
      "\n",
      "Running model (trial=2, mod=209, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  8963.78710938\n",
      "Validation Loss:  8963.78710938\n",
      "Final Training Loss:  8963.78710938\n",
      "Final Validation Loss:  8963.78710938\n",
      "\n",
      "Running model (trial=2, mod=210, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59493172\n",
      "Validation Loss:  0.59493166\n",
      "Final Training Loss:  0.59493172\n",
      "Final Validation Loss:  0.59493166\n",
      "\n",
      "Running model (trial=2, mod=211, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59674364\n",
      "Validation Loss:  0.59674364\n",
      "Final Training Loss:  0.59674364\n",
      "Final Validation Loss:  0.59674364\n",
      "\n",
      "Running model (trial=2, mod=212, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59630418\n",
      "Validation Loss:  0.59630424\n",
      "Final Training Loss:  0.59630418\n",
      "Final Validation Loss:  0.59630424\n",
      "\n",
      "Running model (trial=2, mod=213, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59552538\n",
      "Validation Loss:  0.59552532\n",
      "Final Training Loss:  0.59552538\n",
      "Final Validation Loss:  0.59552532\n",
      "\n",
      "Running model (trial=2, mod=214, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00045776\n",
      "Validation Loss:  501.00045776\n",
      "Final Training Loss:  501.00045776\n",
      "Final Validation Loss:  501.00045776\n",
      "\n",
      "Running model (trial=2, mod=215, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.0\n",
      "Validation Loss:  501.0\n",
      "Final Training Loss:  501.0\n",
      "Final Validation Loss:  501.0\n",
      "\n",
      "Running model (trial=3, mod=216, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60128599\n",
      "Validation Loss:  0.60128599\n",
      "Final Training Loss:  0.60128599\n",
      "Final Validation Loss:  0.60128599\n",
      "\n",
      "Running model (trial=3, mod=217, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60180134\n",
      "Validation Loss:  0.6018014\n",
      "Final Training Loss:  0.60180134\n",
      "Final Validation Loss:  0.6018014\n",
      "\n",
      "Running model (trial=3, mod=218, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60654837\n",
      "Validation Loss:  0.60654843\n",
      "Final Training Loss:  0.60654837\n",
      "Final Validation Loss:  0.60654843\n",
      "\n",
      "Running model (trial=3, mod=219, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.72037458\n",
      "Validation Loss:  0.72037458\n",
      "Final Training Loss:  0.72037458\n",
      "Final Validation Loss:  0.72037458\n",
      "\n",
      "Running model (trial=3, mod=220, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59324515\n",
      "Validation Loss:  0.59324515\n",
      "Final Training Loss:  0.59324515\n",
      "Final Validation Loss:  0.59324515\n",
      "\n",
      "Running model (trial=3, mod=221, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.5907948\n",
      "Validation Loss:  0.59079474\n",
      "Final Training Loss:  0.5907948\n",
      "Final Validation Loss:  0.59079474\n",
      "\n",
      "Running model (trial=3, mod=222, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59777969\n",
      "Validation Loss:  0.59777975\n",
      "Final Training Loss:  0.59777969\n",
      "Final Validation Loss:  0.59777975\n",
      "\n",
      "Running model (trial=3, mod=223, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.5928207\n",
      "Validation Loss:  0.59282076\n",
      "Final Training Loss:  0.5928207\n",
      "Final Validation Loss:  0.59282076\n",
      "\n",
      "Running model (trial=3, mod=224, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59482789\n",
      "Validation Loss:  0.59482795\n",
      "Final Training Loss:  0.59482789\n",
      "Final Validation Loss:  0.59482795\n",
      "\n",
      "Running model (trial=3, mod=225, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  500.99707031\n",
      "Validation Loss:  500.99707031\n",
      "Final Training Loss:  500.99707031\n",
      "Final Validation Loss:  500.99707031\n",
      "\n",
      "Running model (trial=3, mod=226, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00018311\n",
      "Validation Loss:  501.00018311\n",
      "Final Training Loss:  501.00018311\n",
      "Final Validation Loss:  501.00018311\n",
      "\n",
      "Running model (trial=3, mod=227, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00006104\n",
      "Validation Loss:  501.00006104\n",
      "Final Training Loss:  501.00006104\n",
      "Final Validation Loss:  501.00006104\n",
      "\n",
      "Running model (trial=3, mod=228, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60162777\n",
      "Validation Loss:  0.60162777\n",
      "Final Training Loss:  0.60162777\n",
      "Final Validation Loss:  0.60162777\n",
      "\n",
      "Running model (trial=3, mod=229, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59228969\n",
      "Validation Loss:  0.59228969\n",
      "Final Training Loss:  0.59228969\n",
      "Final Validation Loss:  0.59228969\n",
      "\n",
      "Running model (trial=3, mod=230, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60170877\n",
      "Validation Loss:  0.60170871\n",
      "Final Training Loss:  0.60170877\n",
      "Final Validation Loss:  0.60170871\n",
      "\n",
      "Running model (trial=3, mod=231, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  1.01802969\n",
      "Validation Loss:  1.01802969\n",
      "Final Training Loss:  1.01802969\n",
      "Final Validation Loss:  1.01802969\n",
      "\n",
      "Running model (trial=3, mod=232, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  8216.73339844\n",
      "Validation Loss:  8216.73339844\n",
      "Final Training Loss:  8216.73339844\n",
      "Final Validation Loss:  8216.73339844\n",
      "\n",
      "Running model (trial=3, mod=233, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  nan\n",
      "Validation Loss:  nan\n",
      "Final Training Loss:  nan\n",
      "Final Validation Loss:  nan\n",
      "\n",
      "Running model (trial=3, mod=234, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60568035\n",
      "Validation Loss:  0.60568035\n",
      "Final Training Loss:  0.60568035\n",
      "Final Validation Loss:  0.60568035\n",
      "\n",
      "Running model (trial=3, mod=235, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59175825\n",
      "Validation Loss:  0.59175825\n",
      "Final Training Loss:  0.59175825\n",
      "Final Validation Loss:  0.59175825\n",
      "\n",
      "Running model (trial=3, mod=236, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59721327\n",
      "Validation Loss:  0.59721327\n",
      "Final Training Loss:  0.59721327\n",
      "Final Validation Loss:  0.59721327\n",
      "\n",
      "Running model (trial=3, mod=237, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  500.99749756\n",
      "Validation Loss:  500.99749756\n",
      "Final Training Loss:  500.99749756\n",
      "Final Validation Loss:  500.99749756\n",
      "\n",
      "Running model (trial=3, mod=238, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00012207\n",
      "Validation Loss:  501.00012207\n",
      "Final Training Loss:  501.00012207\n",
      "Final Validation Loss:  501.00012207\n",
      "\n",
      "Running model (trial=3, mod=239, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00018311\n",
      "Validation Loss:  501.00018311\n",
      "Final Training Loss:  501.00018311\n",
      "Final Validation Loss:  501.00018311\n",
      "\n",
      "Running model (trial=3, mod=240, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60466856\n",
      "Validation Loss:  0.6046685\n",
      "Final Training Loss:  0.60466856\n",
      "Final Validation Loss:  0.6046685\n",
      "\n",
      "Running model (trial=3, mod=241, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59628665\n",
      "Validation Loss:  0.59628665\n",
      "Final Training Loss:  0.59628665\n",
      "Final Validation Loss:  0.59628665\n",
      "\n",
      "Running model (trial=3, mod=242, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59037292\n",
      "Validation Loss:  0.59037286\n",
      "Final Training Loss:  0.59037292\n",
      "Final Validation Loss:  0.59037286\n",
      "\n",
      "Running model (trial=3, mod=243, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59185755\n",
      "Validation Loss:  0.59185755\n",
      "Final Training Loss:  0.59185755\n",
      "Final Validation Loss:  0.59185755\n",
      "\n",
      "Running model (trial=3, mod=244, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  57.35824585\n",
      "Validation Loss:  57.35824585\n",
      "Final Training Loss:  57.35824585\n",
      "Final Validation Loss:  57.35824585\n",
      "\n",
      "Running model (trial=3, mod=245, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  35.96174622\n",
      "Validation Loss:  35.96174622\n",
      "Final Training Loss:  35.96174622\n",
      "Final Validation Loss:  35.96174622\n",
      "\n",
      "Running model (trial=3, mod=246, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60222232\n",
      "Validation Loss:  0.60222238\n",
      "Final Training Loss:  0.60222232\n",
      "Final Validation Loss:  0.60222238\n",
      "\n",
      "Running model (trial=3, mod=247, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59475142\n",
      "Validation Loss:  0.59475142\n",
      "Final Training Loss:  0.59475142\n",
      "Final Validation Loss:  0.59475142\n",
      "\n",
      "Running model (trial=3, mod=248, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59466308\n",
      "Validation Loss:  0.59466302\n",
      "Final Training Loss:  0.59466308\n",
      "Final Validation Loss:  0.59466302\n",
      "\n",
      "Running model (trial=3, mod=249, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  500.99612427\n",
      "Validation Loss:  500.99612427\n",
      "Final Training Loss:  500.99612427\n",
      "Final Validation Loss:  500.99612427\n",
      "\n",
      "Running model (trial=3, mod=250, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00009155\n",
      "Validation Loss:  501.00009155\n",
      "Final Training Loss:  501.00009155\n",
      "Final Validation Loss:  501.00009155\n",
      "\n",
      "Running model (trial=3, mod=251, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00006104\n",
      "Validation Loss:  501.00006104\n",
      "Final Training Loss:  501.00006104\n",
      "Final Validation Loss:  501.00006104\n",
      "\n",
      "Running model (trial=3, mod=252, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.86140585\n",
      "Validation Loss:  0.86140597\n",
      "Final Training Loss:  0.86140585\n",
      "Final Validation Loss:  0.86140597\n",
      "\n",
      "Running model (trial=3, mod=253, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.5958482\n",
      "Validation Loss:  0.5958482\n",
      "Final Training Loss:  0.5958482\n",
      "Final Validation Loss:  0.5958482\n",
      "\n",
      "Running model (trial=3, mod=254, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59610963\n",
      "Validation Loss:  0.59610963\n",
      "Final Training Loss:  0.59610963\n",
      "Final Validation Loss:  0.59610963\n",
      "\n",
      "Running model (trial=3, mod=255, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  2.54697967\n",
      "Validation Loss:  2.5469799\n",
      "Final Training Loss:  2.54697967\n",
      "Final Validation Loss:  2.5469799\n",
      "\n",
      "Running model (trial=3, mod=256, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  1.32188964\n",
      "Validation Loss:  1.32188976\n",
      "Final Training Loss:  1.32188964\n",
      "Final Validation Loss:  1.32188976\n",
      "\n",
      "Running model (trial=3, mod=257, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  135.90838623\n",
      "Validation Loss:  135.90838623\n",
      "Final Training Loss:  135.90838623\n",
      "Final Validation Loss:  135.90838623\n",
      "\n",
      "Running model (trial=3, mod=258, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59718984\n",
      "Validation Loss:  0.59718984\n",
      "Final Training Loss:  0.59718984\n",
      "Final Validation Loss:  0.59718984\n",
      "\n",
      "Running model (trial=3, mod=259, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59882224\n",
      "Validation Loss:  0.5988223\n",
      "Final Training Loss:  0.59882224\n",
      "Final Validation Loss:  0.5988223\n",
      "\n",
      "Running model (trial=3, mod=260, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59586322\n",
      "Validation Loss:  0.59586328\n",
      "Final Training Loss:  0.59586322\n",
      "Final Validation Loss:  0.59586328\n",
      "\n",
      "Running model (trial=3, mod=261, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  222.48651123\n",
      "Validation Loss:  222.48651123\n",
      "Final Training Loss:  222.48651123\n",
      "Final Validation Loss:  222.48651123\n",
      "\n",
      "Running model (trial=3, mod=262, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00076294\n",
      "Validation Loss:  501.00076294\n",
      "Final Training Loss:  501.00076294\n",
      "Final Validation Loss:  501.00076294\n",
      "\n",
      "Running model (trial=3, mod=263, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00024414\n",
      "Validation Loss:  501.00024414\n",
      "Final Training Loss:  501.00024414\n",
      "Final Validation Loss:  501.00024414\n",
      "\n",
      "Running model (trial=3, mod=264, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59913379\n",
      "Validation Loss:  0.59913379\n",
      "Final Training Loss:  0.59913379\n",
      "Final Validation Loss:  0.59913379\n",
      "\n",
      "Running model (trial=3, mod=265, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59645021\n",
      "Validation Loss:  0.59645015\n",
      "Final Training Loss:  0.59645021\n",
      "Final Validation Loss:  0.59645015\n",
      "\n",
      "Running model (trial=3, mod=266, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59219056\n",
      "Validation Loss:  0.59219056\n",
      "Final Training Loss:  0.59219056\n",
      "Final Validation Loss:  0.59219056\n",
      "\n",
      "Running model (trial=3, mod=267, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59836692\n",
      "Validation Loss:  0.59836686\n",
      "Final Training Loss:  0.59836692\n",
      "Final Validation Loss:  0.59836686\n",
      "\n",
      "Running model (trial=3, mod=268, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.71279794\n",
      "Validation Loss:  0.712798\n",
      "Final Training Loss:  0.71279794\n",
      "Final Validation Loss:  0.712798\n",
      "\n",
      "Running model (trial=3, mod=269, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  346.59848022\n",
      "Validation Loss:  346.59848022\n",
      "Final Training Loss:  346.59848022\n",
      "Final Validation Loss:  346.59848022\n",
      "\n",
      "Running model (trial=3, mod=270, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59672427\n",
      "Validation Loss:  0.59672433\n",
      "Final Training Loss:  0.59672427\n",
      "Final Validation Loss:  0.59672433\n",
      "\n",
      "Running model (trial=3, mod=271, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.6046856\n",
      "Validation Loss:  0.6046856\n",
      "Final Training Loss:  0.6046856\n",
      "Final Validation Loss:  0.6046856\n",
      "\n",
      "Running model (trial=3, mod=272, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59590083\n",
      "Validation Loss:  0.59590089\n",
      "Final Training Loss:  0.59590083\n",
      "Final Validation Loss:  0.59590089\n",
      "\n",
      "Running model (trial=3, mod=273, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.61704618\n",
      "Validation Loss:  0.61704618\n",
      "Final Training Loss:  0.61704618\n",
      "Final Validation Loss:  0.61704618\n",
      "\n",
      "Running model (trial=3, mod=274, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00021362\n",
      "Validation Loss:  501.00021362\n",
      "Final Training Loss:  501.00021362\n",
      "Final Validation Loss:  501.00021362\n",
      "\n",
      "Running model (trial=3, mod=275, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00030518\n",
      "Validation Loss:  501.00030518\n",
      "Final Training Loss:  501.00030518\n",
      "Final Validation Loss:  501.00030518\n",
      "\n",
      "Running model (trial=3, mod=276, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60142452\n",
      "Validation Loss:  0.60142457\n",
      "Final Training Loss:  0.60142452\n",
      "Final Validation Loss:  0.60142457\n",
      "\n",
      "Running model (trial=3, mod=277, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60104156\n",
      "Validation Loss:  0.60104156\n",
      "Final Training Loss:  0.60104156\n",
      "Final Validation Loss:  0.60104156\n",
      "\n",
      "Running model (trial=3, mod=278, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59485942\n",
      "Validation Loss:  0.59485942\n",
      "Final Training Loss:  0.59485942\n",
      "Final Validation Loss:  0.59485942\n",
      "\n",
      "Running model (trial=3, mod=279, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.77599466\n",
      "Validation Loss:  0.77599478\n",
      "Final Training Loss:  0.77599466\n",
      "Final Validation Loss:  0.77599478\n",
      "\n",
      "Running model (trial=3, mod=280, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  277.90060425\n",
      "Validation Loss:  277.90060425\n",
      "Final Training Loss:  277.90060425\n",
      "Final Validation Loss:  277.90060425\n",
      "\n",
      "Running model (trial=3, mod=281, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  2477.11743164\n",
      "Validation Loss:  2477.11743164\n",
      "Final Training Loss:  2477.11743164\n",
      "Final Validation Loss:  2477.11743164\n",
      "\n",
      "Running model (trial=3, mod=282, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59567869\n",
      "Validation Loss:  0.59567869\n",
      "Final Training Loss:  0.59567869\n",
      "Final Validation Loss:  0.59567869\n",
      "\n",
      "Running model (trial=3, mod=283, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59809703\n",
      "Validation Loss:  0.59809709\n",
      "Final Training Loss:  0.59809703\n",
      "Final Validation Loss:  0.59809709\n",
      "\n",
      "Running model (trial=3, mod=284, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59938931\n",
      "Validation Loss:  0.59938937\n",
      "Final Training Loss:  0.59938931\n",
      "Final Validation Loss:  0.59938937\n",
      "\n",
      "Running model (trial=3, mod=285, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59679157\n",
      "Validation Loss:  0.59679163\n",
      "Final Training Loss:  0.59679157\n",
      "Final Validation Loss:  0.59679163\n",
      "\n",
      "Running model (trial=3, mod=286, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.0007019\n",
      "Validation Loss:  501.0007019\n",
      "Final Training Loss:  501.0007019\n",
      "Final Validation Loss:  501.0007019\n",
      "\n",
      "Running model (trial=3, mod=287, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.0\n",
      "Validation Loss:  501.0\n",
      "Final Training Loss:  501.0\n",
      "Final Validation Loss:  501.0\n",
      "\n",
      "Running model (trial=4, mod=288, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59502059\n",
      "Validation Loss:  0.59502059\n",
      "Final Training Loss:  0.59502059\n",
      "Final Validation Loss:  0.59502059\n",
      "\n",
      "Running model (trial=4, mod=289, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.61688501\n",
      "Validation Loss:  0.61688501\n",
      "Final Training Loss:  0.61688501\n",
      "Final Validation Loss:  0.61688501\n",
      "\n",
      "Running model (trial=4, mod=290, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59792167\n",
      "Validation Loss:  0.59792173\n",
      "Final Training Loss:  0.59792167\n",
      "Final Validation Loss:  0.59792173\n",
      "\n",
      "Running model (trial=4, mod=291, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59801459\n",
      "Validation Loss:  0.59801465\n",
      "Final Training Loss:  0.59801459\n",
      "Final Validation Loss:  0.59801465\n",
      "\n",
      "Running model (trial=4, mod=292, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.61778289\n",
      "Validation Loss:  0.61778289\n",
      "Final Training Loss:  0.61778289\n",
      "Final Validation Loss:  0.61778289\n",
      "\n",
      "Running model (trial=4, mod=293, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  1.21780574\n",
      "Validation Loss:  1.21780586\n",
      "Final Training Loss:  1.21780574\n",
      "Final Validation Loss:  1.21780586\n",
      "\n",
      "Running model (trial=4, mod=294, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59457397\n",
      "Validation Loss:  0.59457397\n",
      "Final Training Loss:  0.59457397\n",
      "Final Validation Loss:  0.59457397\n",
      "\n",
      "Running model (trial=4, mod=295, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59477365\n",
      "Validation Loss:  0.59477371\n",
      "Final Training Loss:  0.59477365\n",
      "Final Validation Loss:  0.59477371\n",
      "\n",
      "Running model (trial=4, mod=296, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.6067971\n",
      "Validation Loss:  0.60679704\n",
      "Final Training Loss:  0.6067971\n",
      "Final Validation Loss:  0.60679704\n",
      "\n",
      "Running model (trial=4, mod=297, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  500.99319458\n",
      "Validation Loss:  500.99319458\n",
      "Final Training Loss:  500.99319458\n",
      "Final Validation Loss:  500.99319458\n",
      "\n",
      "Running model (trial=4, mod=298, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00012207\n",
      "Validation Loss:  501.00012207\n",
      "Final Training Loss:  501.00012207\n",
      "Final Validation Loss:  501.00012207\n",
      "\n",
      "Running model (trial=4, mod=299, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00012207\n",
      "Validation Loss:  501.00012207\n",
      "Final Training Loss:  501.00012207\n",
      "Final Validation Loss:  501.00012207\n",
      "\n",
      "Running model (trial=4, mod=300, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60397649\n",
      "Validation Loss:  0.60397649\n",
      "Final Training Loss:  0.60397649\n",
      "Final Validation Loss:  0.60397649\n",
      "\n",
      "Running model (trial=4, mod=301, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60325706\n",
      "Validation Loss:  0.60325706\n",
      "Final Training Loss:  0.60325706\n",
      "Final Validation Loss:  0.60325706\n",
      "\n",
      "Running model (trial=4, mod=302, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.61633027\n",
      "Validation Loss:  0.61633027\n",
      "Final Training Loss:  0.61633027\n",
      "Final Validation Loss:  0.61633027\n",
      "\n",
      "Running model (trial=4, mod=303, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.5945465\n",
      "Validation Loss:  0.59454656\n",
      "Final Training Loss:  0.5945465\n",
      "Final Validation Loss:  0.59454656\n",
      "\n",
      "Running model (trial=4, mod=304, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.63315672\n",
      "Validation Loss:  0.63315678\n",
      "Final Training Loss:  0.63315672\n",
      "Final Validation Loss:  0.63315678\n",
      "\n",
      "Running model (trial=4, mod=305, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  278.01974487\n",
      "Validation Loss:  278.01974487\n",
      "Final Training Loss:  278.01974487\n",
      "Final Validation Loss:  278.01974487\n",
      "\n",
      "Running model (trial=4, mod=306, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59475994\n",
      "Validation Loss:  0.59475988\n",
      "Final Training Loss:  0.59475994\n",
      "Final Validation Loss:  0.59475988\n",
      "\n",
      "Running model (trial=4, mod=307, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59367013\n",
      "Validation Loss:  0.59367013\n",
      "Final Training Loss:  0.59367013\n",
      "Final Validation Loss:  0.59367013\n",
      "\n",
      "Running model (trial=4, mod=308, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59178257\n",
      "Validation Loss:  0.59178257\n",
      "Final Training Loss:  0.59178257\n",
      "Final Validation Loss:  0.59178257\n",
      "\n",
      "Running model (trial=4, mod=309, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  500.99526978\n",
      "Validation Loss:  500.99526978\n",
      "Final Training Loss:  500.99526978\n",
      "Final Validation Loss:  500.99526978\n",
      "\n",
      "Running model (trial=4, mod=310, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00009155\n",
      "Validation Loss:  501.00009155\n",
      "Final Training Loss:  501.00009155\n",
      "Final Validation Loss:  501.00009155\n",
      "\n",
      "Running model (trial=4, mod=311, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00018311\n",
      "Validation Loss:  501.00018311\n",
      "Final Training Loss:  501.00018311\n",
      "Final Validation Loss:  501.00018311\n",
      "\n",
      "Running model (trial=4, mod=312, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.6036545\n",
      "Validation Loss:  0.60365444\n",
      "Final Training Loss:  0.6036545\n",
      "Final Validation Loss:  0.60365444\n",
      "\n",
      "Running model (trial=4, mod=313, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60271025\n",
      "Validation Loss:  0.60271025\n",
      "Final Training Loss:  0.60271025\n",
      "Final Validation Loss:  0.60271025\n",
      "\n",
      "Running model (trial=4, mod=314, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60355806\n",
      "Validation Loss:  0.60355812\n",
      "Final Training Loss:  0.60355806\n",
      "Final Validation Loss:  0.60355812\n",
      "\n",
      "Running model (trial=4, mod=315, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.70586234\n",
      "Validation Loss:  0.7058624\n",
      "Final Training Loss:  0.70586234\n",
      "Final Validation Loss:  0.7058624\n",
      "\n",
      "Running model (trial=4, mod=316, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  nan\n",
      "Validation Loss:  nan\n",
      "Final Training Loss:  nan\n",
      "Final Validation Loss:  nan\n",
      "\n",
      "Running model (trial=4, mod=317, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  3717.33447266\n",
      "Validation Loss:  3717.33447266\n",
      "Final Training Loss:  3717.33447266\n",
      "Final Validation Loss:  3717.33447266\n",
      "\n",
      "Running model (trial=4, mod=318, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.6055212\n",
      "Validation Loss:  0.6055212\n",
      "Final Training Loss:  0.6055212\n",
      "Final Validation Loss:  0.6055212\n",
      "\n",
      "Running model (trial=4, mod=319, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60519296\n",
      "Validation Loss:  0.60519308\n",
      "Final Training Loss:  0.60519296\n",
      "Final Validation Loss:  0.60519308\n",
      "\n",
      "Running model (trial=4, mod=320, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59393787\n",
      "Validation Loss:  0.59393781\n",
      "Final Training Loss:  0.59393787\n",
      "Final Validation Loss:  0.59393781\n",
      "\n",
      "Running model (trial=4, mod=321, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  500.99884033\n",
      "Validation Loss:  500.99884033\n",
      "Final Training Loss:  500.99884033\n",
      "Final Validation Loss:  500.99884033\n",
      "\n",
      "Running model (trial=4, mod=322, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00015259\n",
      "Validation Loss:  501.00015259\n",
      "Final Training Loss:  501.00015259\n",
      "Final Validation Loss:  501.00015259\n",
      "\n",
      "Running model (trial=4, mod=323, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00012207\n",
      "Validation Loss:  501.00012207\n",
      "Final Training Loss:  501.00012207\n",
      "Final Validation Loss:  501.00012207\n",
      "\n",
      "Running model (trial=4, mod=324, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60226601\n",
      "Validation Loss:  0.60226607\n",
      "Final Training Loss:  0.60226601\n",
      "Final Validation Loss:  0.60226607\n",
      "\n",
      "Running model (trial=4, mod=325, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59557968\n",
      "Validation Loss:  0.59557968\n",
      "Final Training Loss:  0.59557968\n",
      "Final Validation Loss:  0.59557968\n",
      "\n",
      "Running model (trial=4, mod=326, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59469545\n",
      "Validation Loss:  0.59469545\n",
      "Final Training Loss:  0.59469545\n",
      "Final Validation Loss:  0.59469545\n",
      "\n",
      "Running model (trial=4, mod=327, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59192753\n",
      "Validation Loss:  0.59192753\n",
      "Final Training Loss:  0.59192753\n",
      "Final Validation Loss:  0.59192753\n",
      "\n",
      "Running model (trial=4, mod=328, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  1.40282893\n",
      "Validation Loss:  1.40282869\n",
      "Final Training Loss:  1.40282893\n",
      "Final Validation Loss:  1.40282869\n",
      "\n",
      "Running model (trial=4, mod=329, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  10435.31738281\n",
      "Validation Loss:  10435.31738281\n",
      "Final Training Loss:  10435.31738281\n",
      "Final Validation Loss:  10435.31738281\n",
      "\n",
      "Running model (trial=4, mod=330, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60658693\n",
      "Validation Loss:  0.60658705\n",
      "Final Training Loss:  0.60658693\n",
      "Final Validation Loss:  0.60658705\n",
      "\n",
      "Running model (trial=4, mod=331, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60614061\n",
      "Validation Loss:  0.60614067\n",
      "Final Training Loss:  0.60614061\n",
      "Final Validation Loss:  0.60614067\n",
      "\n",
      "Running model (trial=4, mod=332, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59943837\n",
      "Validation Loss:  0.59943837\n",
      "Final Training Loss:  0.59943837\n",
      "Final Validation Loss:  0.59943837\n",
      "\n",
      "Running model (trial=4, mod=333, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59360093\n",
      "Validation Loss:  0.59360099\n",
      "Final Training Loss:  0.59360093\n",
      "Final Validation Loss:  0.59360099\n",
      "\n",
      "Running model (trial=4, mod=334, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00030518\n",
      "Validation Loss:  501.00030518\n",
      "Final Training Loss:  501.00030518\n",
      "Final Validation Loss:  501.00030518\n",
      "\n",
      "Running model (trial=4, mod=335, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00018311\n",
      "Validation Loss:  501.00018311\n",
      "Final Training Loss:  501.00018311\n",
      "Final Validation Loss:  501.00018311\n",
      "\n",
      "Running model (trial=4, mod=336, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59636396\n",
      "Validation Loss:  0.5963639\n",
      "Final Training Loss:  0.59636396\n",
      "Final Validation Loss:  0.5963639\n",
      "\n",
      "Running model (trial=4, mod=337, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.5998463\n",
      "Validation Loss:  0.5998463\n",
      "Final Training Loss:  0.5998463\n",
      "Final Validation Loss:  0.5998463\n",
      "\n",
      "Running model (trial=4, mod=338, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59482241\n",
      "Validation Loss:  0.59482235\n",
      "Final Training Loss:  0.59482241\n",
      "Final Validation Loss:  0.59482235\n",
      "\n",
      "Running model (trial=4, mod=339, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.67601126\n",
      "Validation Loss:  0.67601126\n",
      "Final Training Loss:  0.67601126\n",
      "Final Validation Loss:  0.67601126\n",
      "\n",
      "Running model (trial=4, mod=340, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.71856374\n",
      "Validation Loss:  0.71856374\n",
      "Final Training Loss:  0.71856374\n",
      "Final Validation Loss:  0.71856374\n",
      "\n",
      "Running model (trial=4, mod=341, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  12445.90039062\n",
      "Validation Loss:  12445.90039062\n",
      "Final Training Loss:  12445.90039062\n",
      "Final Validation Loss:  12445.90039062\n",
      "\n",
      "Running model (trial=4, mod=342, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.600223\n",
      "Validation Loss:  0.60022295\n",
      "Final Training Loss:  0.600223\n",
      "Final Validation Loss:  0.60022295\n",
      "\n",
      "Running model (trial=4, mod=343, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.6043942\n",
      "Validation Loss:  0.6043942\n",
      "Final Training Loss:  0.6043942\n",
      "Final Validation Loss:  0.6043942\n",
      "\n",
      "Running model (trial=4, mod=344, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.5928458\n",
      "Validation Loss:  0.5928458\n",
      "Final Training Loss:  0.5928458\n",
      "Final Validation Loss:  0.5928458\n",
      "\n",
      "Running model (trial=4, mod=345, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  500.97805786\n",
      "Validation Loss:  500.97805786\n",
      "Final Training Loss:  500.97805786\n",
      "Final Validation Loss:  500.97805786\n",
      "\n",
      "Running model (trial=4, mod=346, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00048828\n",
      "Validation Loss:  501.00048828\n",
      "Final Training Loss:  501.00048828\n",
      "Final Validation Loss:  501.00048828\n",
      "\n",
      "Running model (trial=4, mod=347, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00024414\n",
      "Validation Loss:  501.00024414\n",
      "Final Training Loss:  501.00024414\n",
      "Final Validation Loss:  501.00024414\n",
      "\n",
      "Running model (trial=4, mod=348, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.61384755\n",
      "Validation Loss:  0.61384749\n",
      "Final Training Loss:  0.61384755\n",
      "Final Validation Loss:  0.61384749\n",
      "\n",
      "Running model (trial=4, mod=349, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59735316\n",
      "Validation Loss:  0.59735322\n",
      "Final Training Loss:  0.59735316\n",
      "Final Validation Loss:  0.59735322\n",
      "\n",
      "Running model (trial=4, mod=350, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.67173338\n",
      "Validation Loss:  0.67173344\n",
      "Final Training Loss:  0.67173338\n",
      "Final Validation Loss:  0.67173344\n",
      "\n",
      "Running model (trial=4, mod=351, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.71745521\n",
      "Validation Loss:  0.71745527\n",
      "Final Training Loss:  0.71745521\n",
      "Final Validation Loss:  0.71745527\n",
      "\n",
      "Running model (trial=4, mod=352, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.98736095\n",
      "Validation Loss:  0.98736089\n",
      "Final Training Loss:  0.98736095\n",
      "Final Validation Loss:  0.98736089\n",
      "\n",
      "Running model (trial=4, mod=353, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  7954.42138672\n",
      "Validation Loss:  7954.42138672\n",
      "Final Training Loss:  7954.42138672\n",
      "Final Validation Loss:  7954.42138672\n",
      "\n",
      "Running model (trial=4, mod=354, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59700662\n",
      "Validation Loss:  0.59700668\n",
      "Final Training Loss:  0.59700662\n",
      "Final Validation Loss:  0.59700668\n",
      "\n",
      "Running model (trial=4, mod=355, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60228598\n",
      "Validation Loss:  0.60228598\n",
      "Final Training Loss:  0.60228598\n",
      "Final Validation Loss:  0.60228598\n",
      "\n",
      "Running model (trial=4, mod=356, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.60350293\n",
      "Validation Loss:  0.60350293\n",
      "Final Training Loss:  0.60350293\n",
      "Final Validation Loss:  0.60350293\n",
      "\n",
      "Running model (trial=4, mod=357, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  0.59297067\n",
      "Validation Loss:  0.59297067\n",
      "Final Training Loss:  0.59297067\n",
      "Final Validation Loss:  0.59297067\n",
      "\n",
      "Running model (trial=4, mod=358, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00036621\n",
      "Validation Loss:  501.00036621\n",
      "Final Training Loss:  501.00036621\n",
      "Final Validation Loss:  501.00036621\n",
      "\n",
      "Running model (trial=4, mod=359, k=0):\n",
      "################################  0  ################################\n",
      "Training Loss:  501.00006104\n",
      "Validation Loss:  501.00006104\n",
      "Final Training Loss:  501.00006104\n",
      "Final Validation Loss:  501.00006104\n"
     ]
    }
   ],
   "source": [
    "cv_results = k_fold_cv_grid(\n",
    "    model_params=exp_model_params_iter,\n",
    "    fit=fit_FFNN,\n",
    "    training_params=exp_training_params_iter,\n",
    "    data=data,\n",
    "    folds=FOLDS,\n",
    "    verbose=True,\n",
    "    trials=5\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plotting\n",
    "x_train_ = x_train.detach()\n",
    "x_sorted, indices = torch.sort(x_train_, dim=0)\n",
    "\n",
    "plot_kwargs = {\n",
    "    \"x_test\": x_sorted,\n",
    "    \"x_train\": x_sorted,\n",
    "    \"y_train\": c3.ksi(x_sorted),\n",
    "    \"x_axis\": \"t\",\n",
    "    \"y_axis\": \"$\\\\xi(t)$\",\n",
    "}\n",
    "plot_result(\n",
    "    path_figures=PATH_FIGURES,\n",
    "    plot_name=SET_NAME,\n",
    "    **cv_results,\n",
    "    plot_function=plot_model_1d,\n",
    "    function_kwargs=plot_kwargs,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "models = cv_results[\"models\"]\n",
    "\n",
    "parameters = np.vectorize(lambda model: sum(p.numel() for p in model.parameters()))(models)\n",
    "layers = np.vectorize(lambda model: model.n_hidden_layers)(models)\n",
    "neurons = np.vectorize(lambda model: model.neurons)(models)\n",
    "loss_array = np.vectorize(lambda model: loss_func(model, x_train, q_train).detach())(models)\n",
    "loss_array -= c3.DIST_R_Q"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(layers,loss_array)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylabel(\"Error\")\n",
    "ax.set_xlabel(\"Layers\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(parameters,loss_array)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylabel(\"Error\")\n",
    "ax.set_xlabel(\"Number of parameters\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(neurons,loss_array)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylabel(\"Error\")\n",
    "ax.set_xlabel(\"Neurons per layer\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fmri = sns.load_dataset(\"fmri\")\n",
    "sns.relplot(x=parameters.ravel(), y=loss_array.ravel(), kind=\"line\");\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}