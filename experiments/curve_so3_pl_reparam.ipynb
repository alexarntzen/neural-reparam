{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Test on piecewise linear curves in $SO(3)^n$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "from itertools import chain\n",
    "set_matplotlib_formats('pdf', 'svg')\n",
    "\n",
    "# torch.set_default_dtype(torch.float64)\n",
    "from deepthermal.FFNN_model import fit_FFNN, FFNN, init_xavier\n",
    "from deepthermal.validation import create_subdictionary_iterator, k_fold_cv_grid, add_dictionary_iterators\n",
    "from deepthermal.plotting import plot_result, plot_model_1d\n",
    "\n",
    "from deep_reparametrization.reparametrization import (\n",
    "    get_elastic_metric_loss,\n",
    "    compute_loss_reparam,\n",
    ")\n",
    "from deep_reparametrization.helpers import get_pc_curve_from_data, get_pl_curve_from_data\n",
    "from deep_reparametrization.ResNET import ResNET\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from animation.animation_manager import fetch_animations, unpack\n",
    "from so3.curves import move_origin_to_zero, dynamic_distance\n",
    "from so3.helpers import crop_curve\n",
    "from so3.dynamic_distance import find_optimal_diffeomorphism, create_shared_parameterization\n",
    "from so3.clustering.id_set import crop_curve_based_on_id, get_id_set\n",
    "from so3.transformations import skew_to_vector, SRVT\n",
    "from so3 import animation_to_SO3\n",
    "\n",
    "max_frame_count = 180\n",
    "\n",
    "id_set = get_id_set()\n",
    "print(\"Load data\")\n",
    "\n",
    "data = [fetch_animations(1, file_name=\"39_02.amc\"),  #walk 6.5 steps\n",
    "        fetch_animations(1, file_name=\"35_26.amc\"),  # run/jog 3 steps\n",
    "        fetch_animations(1, file_name=\"16_35.amc\")  # run/jog 3 steps\n",
    "        ]\n",
    "\n",
    "# walk\n",
    "subject, animation, desc0 = unpack(data[2])\n",
    "curve_full = animation_to_SO3(subject, animation)\n",
    "curve = crop_curve(curve_full, stop=240)  #first 2 seconds\n",
    "c_0 = move_origin_to_zero(curve)\n",
    "print(desc0)\n",
    "\n",
    "# run\n",
    "subject, animation, desc1 = unpack(data[1])\n",
    "curve_full = animation_to_SO3(subject, animation)\n",
    "curve = crop_curve(curve_full, stop=240)  #first 2 seconds\n",
    "c_1 = move_origin_to_zero(curve)\n",
    "print(desc1)\n",
    "print(c_0.shape)\n",
    "print(c_1.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    #calculate distances\n",
    "I0 = np.linspace(0, 1, c_0.shape[1])\n",
    "I1 = np.linspace(0, 1, c_1.shape[1])\n",
    "q_data_ = skew_to_vector(SRVT(c_0, I0))\n",
    "r_data_ = skew_to_vector(SRVT(c_1, I1))\n",
    "I, q_data, r_data = create_shared_parameterization(q0=q_data_, q1=r_data_, I0=I0, I1=I1)\n",
    "shared_frames = I.shape[0]\n",
    "q_func = get_pl_curve_from_data(data=q_data)\n",
    "r_func = get_pl_curve_from_data(data=r_data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d_01 = dynamic_distance(c_0, c_1, depth=10)\n",
    "print(d_01)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "I1_new = find_optimal_diffeomorphism(q0=q_data, q1=r_data, I0=I, I1=I, depth=10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "########\n",
    "DIR = \"../figures/curve_so3/\"\n",
    "SET_NAME = \"pl_eks_5\"\n",
    "PATH_FIGURES = os.path.join(DIR, SET_NAME)\n",
    "if not os.path.exists(PATH_FIGURES):\n",
    "    os.makedirs(PATH_FIGURES)\n",
    "########\n",
    "\n",
    "FOLDS = 1\n",
    "N = shared_frames  # training points internal\n",
    "\n",
    "loss_func = get_elastic_metric_loss(r=r_func, constrain_cost=1e4, verbose=False)\n",
    "penalty_free_loss_func = get_elastic_metric_loss(r=r_func, constrain_cost=0, verbose=False)\n",
    "lr_scheduler = lambda optimizer: torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.8, patience=200,\n",
    "                                                                            verbose=True)\n",
    "\n",
    "MODEL_PARAMS = {\n",
    "    \"input_dimension\": [1],\n",
    "    \"output_dimension\": [1],\n",
    "    \"n_hidden_layers\": [2],#,8,16,64],\n",
    "    \"model\": [ResNET],\n",
    "    \"neurons\": [4,16,64,256]\n",
    "}\n",
    "MODEL_PARAMS_2 = {\n",
    "    \"input_dimension\": [1],\n",
    "    \"output_dimension\": [1],\n",
    "    \"model\": [ResNET],\n",
    "    \"n_hidden_layers\": [2,4,8,16,32,64],\n",
    "    \"neurons\": [8],\n",
    "}\n",
    "# extend the previous dict with the zip of this\n",
    "MODEL_PARAMS_EXPERIMENT = {\n",
    "    \"activation\": [\"tanh\", \"relu\"],\n",
    "}\n",
    "TRAINING_PARAMS = {\n",
    "    \"batch_size\": [N],\n",
    "    \"regularization_param\": [0],\n",
    "    \"compute_loss\": [compute_loss_reparam],\n",
    "    \"loss_func\": [loss_func],\n",
    "}\n",
    "# extend the previous dict with the zip of this\n",
    "TRAINING_PARAMS_EXPERIMENT = {\n",
    "    \"optimizer\": [\"ADAM\",],\n",
    "    \"num_epochs\": [2000,],\n",
    "    \"learning_rate\": [0.05,],\n",
    "    \"lr_scheduler\": [lr_scheduler]\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train = torch.linspace(0, 1, N, requires_grad=True).unsqueeze(1)\n",
    "q_train = torch.tensor(q_data)\n",
    "data = TensorDataset(x_train, q_train)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create iterators\n",
    "model_params_iter_1 = create_subdictionary_iterator(MODEL_PARAMS)\n",
    "model_params_iter_2 = create_subdictionary_iterator(MODEL_PARAMS_2)\n",
    "model_params_iter = chain.from_iterable((model_params_iter_1, model_params_iter_2))\n",
    "\n",
    "model_exp_iter = create_subdictionary_iterator(MODEL_PARAMS_EXPERIMENT, product=False)\n",
    "exp_model_params_iter = add_dictionary_iterators(model_exp_iter, model_params_iter)\n",
    "\n",
    "training_params_iter = create_subdictionary_iterator(TRAINING_PARAMS)\n",
    "training_exp_iter = create_subdictionary_iterator(TRAINING_PARAMS_EXPERIMENT, product=False)\n",
    "exp_training_params_iter = add_dictionary_iterators(training_exp_iter, training_params_iter)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Do the actual training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cv_results = k_fold_cv_grid(\n",
    "    model_params=exp_model_params_iter,\n",
    "    fit=fit_FFNN,\n",
    "    training_params=exp_training_params_iter,\n",
    "    data=data,\n",
    "    folds=FOLDS,\n",
    "    verbose=True,\n",
    "    trials=5\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plotting\n",
    "disc_points = x_train.detach()\n",
    "\n",
    "plot_kwargs = {\n",
    "    \"x_test\": disc_points,\n",
    "    \"x_train\": disc_points,\n",
    "    \"y_train\": I1_new,\n",
    "    \"x_axis\": \"t\",\n",
    "    \"y_axis\": \"$\\\\varphi(t)$\",\n",
    "    \"compare_label\": \"DP solution\"\n",
    "}\n",
    "plot_result(\n",
    "    path_figures=PATH_FIGURES,\n",
    "    **cv_results,\n",
    "    plot_function=plot_model_1d,\n",
    "    function_kwargs=plot_kwargs,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models = cv_results[\"models\"]\n",
    "\n",
    "parameters = np.vectorize(lambda model: sum(p.numel() for p in model.parameters()))(models).flatten()\n",
    "model_type = np.vectorize(str)(models).flatten()\n",
    "layers = np.vectorize(lambda model: model.n_hidden_layers)(models).flatten()\n",
    "activation = np.vectorize(lambda model: model.activation)(models).flatten()\n",
    "neurons = np.vectorize(lambda model: model.neurons)(models).flatten()\n",
    "loss_array = np.vectorize(lambda model: penalty_free_loss_func(model, x_train, q_train).detach())(models).flatten()\n",
    "loss_array -= d_01 ** 2\n",
    "# make data frame\n",
    "# optims = [\"line search\", \"ADAM\", \"LBFGS\"]*(len(loss_array)//3)\n",
    "d_results = pd.DataFrame(\n",
    "    {\"loss\": loss_array, \"neurons\": neurons, \"layers\": layers, \"parameters\": parameters, \"model\": model_type,\n",
    "     \"activation\": activation})\n",
    "\n",
    "d_results_layer = d_results[d_results.neurons == 8]\n",
    "d_results_neurons = d_results[d_results.layers == 2]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig_neurons= sns.lineplot(data =d_results_neurons, y=\"loss\",  x=\"neurons\", hue=\"activation\", ci=80, err_style=\"bars\")\n",
    "fig_neurons.set(xscale=\"log\",yscale=\"log\", xlabel=\"Neurons\")\n",
    "fig_neurons.set(ylabel=\"$\\\\Delta E$\")\n",
    "plt.savefig(f\"{PATH_FIGURES}/neurons_error.pdf\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"faled, total:\")\n",
    "print(len(d_results_neurons[d_results_neurons.loss > 10]), len(d_results_neurons))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig_layers= sns.lineplot(data =d_results_layer, y=\"loss\",  x=\"layers\", hue=\"activation\", ci=80, err_style=\"bars\")\n",
    "fig_layers.set(yscale=\"log\", xscale=\"log\",xlabel=\"Layers\", ylabel=\"Error\")\n",
    "fig_layers.set(ylabel=\"$\\\\Delta E$\")\n",
    "plt.savefig(f\"{PATH_FIGURES}/layer_error.pdf\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"faled, total:\")\n",
    "print(len(d_results_layer[d_results_layer.loss\n",
    "                          > 10]), len(d_results_layer))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig_scatter = sns.scatterplot(data =d_results, y=\"loss\",  x=\"parameters\", hue=\"layers\", style=\"model\")\n",
    "fig_neurons.set(ylabel=\"$E$\")\n",
    "fig_scatter.set(yscale=\"log\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}