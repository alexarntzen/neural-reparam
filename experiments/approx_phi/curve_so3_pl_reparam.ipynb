{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on piecewise linear curves in $SO(3)^n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "from itertools import chain\n",
    "\n",
    "set_matplotlib_formats(\"pdf\", \"svg\")\n",
    "\n",
    "from deepthermal.FFNN_model import fit_FFNN, FFNN\n",
    "from deepthermal.validation import (\n",
    "    create_subdictionary_iterator,\n",
    "    k_fold_cv_grid,\n",
    "    add_dictionary_iterators,\n",
    ")\n",
    "from deepthermal.plotting import plot_result, plot_model_1d\n",
    "\n",
    "from neural_reparam.reparametrization import (\n",
    "    get_elastic_metric_loss,\n",
    "    compute_loss_reparam,\n",
    ")\n",
    "from neural_reparam.interpolation import get_pl_curve_from_data\n",
    "from neural_reparam.models import CNN\n",
    "from neural_reparam.ResNet import ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from signatureshape.animation.animation_manager import fetch_animations, unpack\n",
    "from signatureshape.so3.curves import move_origin_to_zero, dynamic_distance\n",
    "from signatureshape.so3.helpers import crop_curve\n",
    "from signatureshape.so3.dynamic_distance import (\n",
    "    find_optimal_diffeomorphism,\n",
    "    create_shared_parameterization,\n",
    ")\n",
    "from signatureshape.so3.transformations import skew_to_vector, SRVT\n",
    "from signatureshape.so3 import animation_to_SO3\n",
    "\n",
    "max_frame_count = 180\n",
    "\n",
    "print(\"Load data\")\n",
    "\n",
    "data = [\n",
    "    fetch_animations(1, file_name=\"39_02.amc\"),  # walk 6.5 steps\n",
    "    fetch_animations(1, file_name=\"35_26.amc\"),  # run/jog 3 steps\n",
    "    fetch_animations(1, file_name=\"16_35.amc\"),  # run/jog 3 steps\n",
    "]\n",
    "\n",
    "# walk\n",
    "subject, animation, desc0 = unpack(data[2])\n",
    "curve_full = animation_to_SO3(subject, animation)\n",
    "curve = crop_curve(curve_full, stop=240)  # first 2 seconds\n",
    "c_0 = move_origin_to_zero(curve)\n",
    "print(desc0)\n",
    "\n",
    "# run\n",
    "subject, animation, desc1 = unpack(data[1])\n",
    "curve_full = animation_to_SO3(subject, animation)\n",
    "curve = crop_curve(curve_full, stop=240)  # first 2 seconds\n",
    "c_1 = move_origin_to_zero(curve)\n",
    "print(desc1)\n",
    "print(c_0.shape)\n",
    "print(c_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distances\n",
    "I0 = np.linspace(0, 1, c_0.shape[1])\n",
    "I1 = np.linspace(0, 1, c_1.shape[1])\n",
    "q_data_ = skew_to_vector(SRVT(c_0, I0))\n",
    "r_data_ = skew_to_vector(SRVT(c_1, I1))\n",
    "I, q_data, r_data = create_shared_parameterization(q0=q_data_, q1=r_data_, I0=I0, I1=I1)\n",
    "shared_frames = I.shape[0]\n",
    "q_func = get_pl_curve_from_data(data=q_data)\n",
    "r_func = get_pl_curve_from_data(data=r_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_01 = dynamic_distance(c_0, c_1, depth=10)\n",
    "print(d_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I1_new = find_optimal_diffeomorphism(q0=q_data, q1=r_data, I0=I, I1=I, depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "DIR = \"../figures/curve_so3/\"\n",
    "SET_NAME = \"pl_eks_7\"\n",
    "PATH_FIGURES = os.path.join(DIR, SET_NAME)\n",
    "if not os.path.exists(PATH_FIGURES):\n",
    "    os.makedirs(PATH_FIGURES)\n",
    "########\n",
    "\n",
    "FOLDS = 1\n",
    "N = shared_frames  # training points internal\n",
    "lr_scheduler = lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optim, mode=\"min\", factor=0.1, patience=5, verbose=True\n",
    ")\n",
    "loss_func = get_elastic_metric_loss(r=r_func, constrain_cost=1e4, verbose=False)\n",
    "penalty_free_loss_func = get_elastic_metric_loss(\n",
    "    r=r_func, constrain_cost=0, verbose=False\n",
    ")\n",
    "\n",
    "MODEL_PARAMS = {\n",
    "    \"input_dimension\": [1],\n",
    "    \"output_dimension\": [1],\n",
    "    \"n_hidden_layers\": [2],  # ,8,16,64],\n",
    "    \"model\": [ResNet],\n",
    "    \"neurons\": [2, 4, 8, 16, 32, 64, 128],\n",
    "}\n",
    "MODEL_PARAMS_2 = {\n",
    "    \"input_dimension\": [1],\n",
    "    \"output_dimension\": [1],\n",
    "    \"model\": [CNN, ResNet],\n",
    "    \"n_hidden_layers\": [1, 2, 4, 8, 16, 32],\n",
    "    \"neurons\": [8],\n",
    "}\n",
    "\n",
    "# extend the previous dict with the zip of this\n",
    "MODEL_PARAMS_EXPERIMENT = {\n",
    "    \"activation\": [\"relu\", \"tanh\"],\n",
    "}\n",
    "TRAINING_PARAMS = {\n",
    "    \"batch_size\": [N // 2],\n",
    "    \"regularization_param\": [0],\n",
    "    \"compute_loss\": [compute_loss_reparam],\n",
    "    \"loss_func\": [loss_func],\n",
    "}\n",
    "# extend the previous dict with the zip of this\n",
    "TRAINING_PARAMS_EXPERIMENT = {\n",
    "    \"optimizer\": [\"strong_wolfe\"],\n",
    "    \"num_epochs\": [100],\n",
    "    \"learning_rate\": [1],\n",
    "    \"stop_stochastic\": [90],\n",
    "    \"lr_scheduler\": [lr_scheduler],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.linspace(0, 1, N, requires_grad=True).unsqueeze(1)\n",
    "q_train = torch.tensor(q_data)\n",
    "data = TensorDataset(x_train, q_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create iterators\n",
    "model_params_iter_1 = create_subdictionary_iterator(MODEL_PARAMS)\n",
    "model_params_iter_2 = create_subdictionary_iterator(MODEL_PARAMS_2)\n",
    "model_params_iter = chain.from_iterable((model_params_iter_1, model_params_iter_2))\n",
    "\n",
    "model_exp_iter = create_subdictionary_iterator(MODEL_PARAMS_EXPERIMENT, product=False)\n",
    "exp_model_params_iter = add_dictionary_iterators(model_exp_iter, model_params_iter)\n",
    "\n",
    "training_params_iter = create_subdictionary_iterator(TRAINING_PARAMS)\n",
    "training_exp_iter = create_subdictionary_iterator(\n",
    "    TRAINING_PARAMS_EXPERIMENT, product=False\n",
    ")\n",
    "exp_training_params_iter = add_dictionary_iterators(\n",
    "    training_exp_iter, training_params_iter\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = k_fold_cv_grid(\n",
    "    model_params=exp_model_params_iter,\n",
    "    fit=fit_FFNN,\n",
    "    training_params=exp_training_params_iter,\n",
    "    data=data,\n",
    "    folds=FOLDS,\n",
    "    verbose=True,\n",
    "    trials=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "disc_points = x_train.detach()\n",
    "\n",
    "plot_kwargs = {\n",
    "    \"x_test\": disc_points,\n",
    "    \"x_train\": disc_points,\n",
    "    \"y_train\": I1_new,\n",
    "    \"x_axis\": \"t\",\n",
    "    \"y_axis\": \"$\\\\varphi(t)$\",\n",
    "    \"compare_label\": \"DP solution\",\n",
    "}\n",
    "plot_result(\n",
    "    path_figures=PATH_FIGURES,\n",
    "    **cv_results,\n",
    "    plot_function=plot_model_1d,\n",
    "    function_kwargs=plot_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = cv_results[\"models\"]\n",
    "\n",
    "parameters = np.vectorize(lambda model: sum(p.numel() for p in model.parameters()))(\n",
    "    models\n",
    ").flatten()\n",
    "model_type = np.vectorize(str)(models).flatten()\n",
    "layers = np.vectorize(lambda model: model.n_hidden_layers)(models).flatten()\n",
    "activation = np.vectorize(lambda model: model.activation)(models).flatten()\n",
    "neurons = np.vectorize(lambda model: model.neurons)(models).flatten()\n",
    "loss_array = np.vectorize(\n",
    "    lambda model: penalty_free_loss_func(model, x_train, q_train).detach()\n",
    ")(models).flatten()\n",
    "loss_array -= d_01**2\n",
    "# make data frame\n",
    "# optims = [\"line search\", \"ADAM\", \"LBFGS\"]*(len(loss_array)//3)\n",
    "d_results = pd.DataFrame(\n",
    "    {\n",
    "        \"loss\": loss_array,\n",
    "        \"neurons\": neurons,\n",
    "        \"layers\": layers,\n",
    "        \"parameters\": parameters,\n",
    "        \"model\": model_type,\n",
    "        \"activation\": activation,\n",
    "    }\n",
    ")\n",
    "\n",
    "d_results_layer = d_results[d_results.neurons == 8]\n",
    "d_results_neurons = d_results[d_results.layers == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_neurons = sns.lineplot(\n",
    "    data=d_results_neurons,\n",
    "    y=\"loss\",\n",
    "    x=\"neurons\",\n",
    "    hue=\"activation\",\n",
    "    ci=80,\n",
    "    err_style=\"bars\",\n",
    ")\n",
    "fig_neurons.set(xscale=\"log\", yscale=\"log\", xlabel=\"Neurons\")\n",
    "fig_neurons.set(ylabel=\"$\\\\Delta E$\")\n",
    "plt.savefig(f\"{PATH_FIGURES}/neurons_error.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"faled, total:\")\n",
    "print(len(d_results_neurons[d_results_neurons.loss > 10]), len(d_results_neurons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_layers = sns.lineplot(\n",
    "    data=d_results_layer,\n",
    "    y=\"loss\",\n",
    "    x=\"layers\",\n",
    "    hue=\"activation\",\n",
    "    ci=80,\n",
    "    err_style=\"bars\",\n",
    ")\n",
    "fig_layers.set(yscale=\"log\", xscale=\"log\", xlabel=\"Hidden layers\", ylabel=\"Error\")\n",
    "fig_layers.set(ylabel=\"$\\\\Delta E$\")\n",
    "plt.savefig(f\"{PATH_FIGURES}/layer_error.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"faled, total:\")\n",
    "print(len(d_results_layer[d_results_layer.loss > 10]), len(d_results_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_scatter = sns.scatterplot(\n",
    "    data=d_results, y=\"loss\", x=\"parameters\", hue=\"layers\", style=\"model\"\n",
    ")\n",
    "fig_neurons.set(ylabel=\"$E$\")\n",
    "fig_scatter.set(yscale=\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_results.to_csv(f\"{PATH_FIGURES}/d_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
